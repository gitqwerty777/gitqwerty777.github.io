<!DOCTYPE html><html lang="zh-TW"><head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.1.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon.png">
  <link rel="mask-icon" href="/img/favicon.png" color="#222">
  <meta name="google-site-verification" content="45plYlJRhxb-g8Tl8seizYgih_JUsmcJRH6oJHplkj0">






<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"gitqwerty777.github.io","root":"/","scheme":"Pisces","version":"7.8.0","exturl":true,"sidebar":{"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"show_result":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideLeftIn"}},"path":"search.json"};
  </script>

  <meta name="description" content="Chap 9 ~ 12 -- How can machine learn?, Chap 13 ~ 16 -- How can machine learn better?">
<meta property="og:type" content="article">
<meta property="og:title" content="機器學習基石(下)">
<meta property="og:url" content="http://gitqwerty777.github.io/MLfoundation2/index.html">
<meta property="og:site_name" content="QWERTY">
<meta property="og:description" content="Chap 9 ~ 12 -- How can machine learn?, Chap 13 ~ 16 -- How can machine learn better?">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/einout2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/residual.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/einmatrix.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/ein=0.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/vectorwdiff.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/invertiblesingular.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/regressionalgo.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-5.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-6.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-7.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-8.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/9-9.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-6.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-7.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-8.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-9.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-11.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-12.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-13.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-14.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-17.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-15.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-16.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-18.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/10-19.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-7.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-8.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-5.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-6.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/11-9.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12-2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12-1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12-4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12_1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13_01.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12_4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12_5.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/12_6.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13_1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-5.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-6.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-01.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-9.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/13-8.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/14-1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/14-2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/14-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/14-4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/14-5.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/15-1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/14-7.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/15-2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/15-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-1.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-2.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-3.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-4.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-5.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-6.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-7.png">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ML/16-8.png">
<meta property="article:published_time" content="2014-10-31T07:45:45.000Z">
<meta property="article:modified_time" content="2022-04-01T16:57:25.640Z">
<meta property="article:author" content="qwerty">
<meta property="article:tag" content="機器學習">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://gitqwerty777.github.io/img/ML/einout2.png">

<link rel="canonical" href="http://gitqwerty777.github.io/MLfoundation2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-TW'
  };
</script>

<script data-ad-client="ca-pub-7267358872858108" async="" src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>

  <title>機器學習基石(下) | QWERTY</title>
  
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=UA-51310670-1"></script>
    <script data-pjax="">
      if (CONFIG.hostname === location.hostname) {
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'UA-51310670-1');
      }
    </script>






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

<link rel="alternate" href="/atom.xml" title="QWERTY" type="application/atom+xml">
<script>function loadCss(l){var d=document,h=d.head,s=d.createElement('link');s.rel='stylesheet';s.href=l;!function e(f){if (d.body)return f();setTimeout(function(){e(f)})}(function(){h.appendChild(s);});}loadCss('/style.css');loadCss('//fonts.googleapis.com/css?family=Noto Sans TC:300,300italic,400,400italic,700,700italic|Cormorant Garamond:300,300italic,400,400italic,700,700italic|Noto Serif TC:300,300italic,400,400italic,700,700italic|Fira Code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext');</script><noscript><link rel="stylesheet" href="/style.css"><link rel="stylesheet" href="//fonts.googleapis.com/css?family=Noto Sans TC:300,300italic,400,400italic,700,700italic|Cormorant Garamond:300,300italic,400,400italic,700,700italic|Noto Serif TC:300,300italic,400,400italic,700,700italic|Fira Code:300,300italic,400,400italic,700,700italic&amp;display=swap&amp;subset=latin,latin-ext"></noscript></head>

<body itemscope="" itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">QWERTY</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Hello World!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>文章<span class="badge">59</span></a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>關於</a>

  </li>
        <li class="menu-item menu-item-rss">

    <a href="/atom.xml" rel="section"><i class="fas fa-rss-square fa-fw"></i>RSS</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤<span class="badge">143</span></a>

  </li>
        <li class="menu-item menu-item-ptt標籤雲">

    <span class="exturl" data-url="aHR0cHM6Ly9xd2VydHk3NzcubWUvcHR0LXRhZy1jbG91ZC8="><i class="fas fa-hashtag fa-fw"></i>PTT標籤雲</span>

  </li>
        <li class="menu-item menu-item-支語警察">

    <a href="/foreign-terms-police" rel="section"><i class="fas fa-language fa-fw"></i>支語警察</a>

  </li>
        <li class="menu-item menu-item-英文聊天機器人">

    <span class="exturl" data-url="aHR0cHM6Ly9jaGF0Ym90LnF3ZXJ0eTc3Ny5tZQ=="><i class="fas fa-comment-dots fa-fw"></i>英文聊天機器人</span>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" placeholder="搜尋..." spellcheck="false" type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dpdHF3ZXJ0eTc3Nw==" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope="" itemtype="http://schema.org/Article" class="post-block" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="http://gitqwerty777.github.io/MLfoundation2/">

    <span hidden="" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/qwerty.png">
      <meta itemprop="name" content="qwerty">
      <meta itemprop="description" content="Programming | Computer Science | Thought">
    </span>

    <span hidden="" itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QWERTY">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          機器學習基石(下)
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">發表於</span>

              <time title="創建時間：2014-10-31 15:45:45" itemprop="dateCreated datePublished" datetime="2014-10-31T15:45:45+08:00">2014-10-31</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分類於</span>
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%AD%86%E8%A8%98/" itemprop="url" rel="index"><span itemprop="name">筆記</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="文章字數">
              <span class="post-meta-item-icon">
                <i class="far fa-file-word"></i>
              </span>
                <span class="post-meta-item-text">文章字數：</span>
              <span>8.1k</span>
            </span>
            <div class="post-description">Chap 9 ~ 12 -- How can machine learn?, Chap 13 ~ 16 -- How can machine learn better?</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="Chap09-Linear-Regression"><a href="#Chap09-Linear-Regression" class="headerlink" title="Chap09 Linear Regression"></a>Chap09 Linear Regression</h2><ul>
<li>將w向量(參數)最佳化<ul>
<li>直接用計算出的 Wx</li>
<li>perceptron → output 只有 +1/-1</li>
<li>regression → output 為數字</li>
</ul>
</li>
<li>找最少誤差 <img data-src="/img/ML/einout2.png"><ul>
<li>wx 和 y 的誤差平方</li>
<li>Ein: 取平均, Eout: 取期望值 </li>
<li><img data-src="/img/ML/residual.png"></li>
</ul>
</li>
</ul>
<span id="more"></span>

<p>轉換成矩陣形式(最後一行的X, y, w都是矩陣)<br><img data-src="/img/ML/einmatrix.png"></p>
<p>Ein(w)函數性質  </p>
<ul>
<li>continuous</li>
<li>differeniable</li>
<li>convex(凸)     </li>
<li>可以找到最低點(使Ein微分 = 0的w) <img data-src="/img/ML/ein=0.png"><ul>
<li>因為 A 為 $X^tX$ 的形式，必為symmetric matrix，可直接做微分 <img data-src="/img/ML/vectorwdiff.png"></li>
</ul>
</li>
</ul>
<p>計算W <img data-src="/img/ML/invertiblesingular.png">   </p>
<ul>
<li>若A invertible，可直接求inverse</li>
<li>若非，則用X十字架(<span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTW9vcmUlRTIlODAlOTNQZW5yb3NlX3BzZXVkb2ludmVyc2U=">pseudo inverse<i class="fa fa-external-link-alt"></i></span>)</li>
</ul>
<h3 id="linear-regression-algorithm-easy"><a href="#linear-regression-algorithm-easy" class="headerlink" title="linear regression algorithm(easy)"></a>linear regression algorithm(easy)</h3><p> <img data-src="/img/ML/regressionalgo.png" alt="linear regression algorithm"></p>
<p>Is it “learning algorithm”?    </p>
<ul>
<li>No → 直接計算所得的解</li>
<li><strong>Yes</strong> → good Ein and Eout(finite $d_vc$), pseudo-inverse<ul>
<li>可視為迭代進行(用矩陣一次算出)</li>
</ul>
</li>
</ul>
<h3 id="“Simpler-than-VC”-Guarantee"><a href="#“Simpler-than-VC”-Guarantee" class="headerlink" title="“Simpler-than-VC” Guarantee"></a>“Simpler-than-VC” Guarantee</h3><p>可證Ein會小於????</p>
<p><img data-src="/img/ML/9-3.png"><br>預測值 $\hat{y} = Xw = XX^{-1}y = Hy$<br>定義 hat matrix $H = XX^{-1}$ </p>
<h4 id="Hat-Matrix-in-Geometry"><a href="#Hat-Matrix-in-Geometry" class="headerlink" title="Hat Matrix in Geometry"></a>Hat Matrix in Geometry</h4><p><img data-src="/img/ML/9-1.png">  </p>
<ul>
<li>預測值 $\hat{y}$ 被限制在X的span上 ($\hat{y} = WX$)</li>
<li>最小誤差會出現在y - $\hat{y}$ 與 span of X 垂直時</li>
<li>H 將向量投影至span of X上</li>
<li>I-H : 投影至與 span of X 垂直的向量 (即為誤差: y - $\hat{y}$)<ul>
<li>可以發現 I-H 對角線上的值之和 trace(I - H) = N - (d + 1)<ul>
<li>其物理意義為在N維空間投影至d+1維空間</li>
</ul>
</li>
</ul>
</li>
<li>with noise <img data-src="/img/ML/9-4.png"><ul>
<li>f(x) + noise → y<ul>
<li>f(x) 為正確的 y</li>
<li>noise * (I-H) = y - $\hat{y}$</li>
</ul>
</li>
<li>可算出Ein和noise的關係: N變大時, Eout↓, Ein↑, noise level收斂在σ^2 <img data-src="/img/ML/9-5.png"> <img data-src="/img/ML/9-6.png"> <img data-src="/img/ML/9-7.png"> <ul>
<li>Eout可用類似方法證明</li>
<li>expected generalization error(= Eout - Ein): 2(d+1)/N</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="Usage"><a href="#Usage" class="headerlink" title="Usage"></a>Usage</h3><p>Run Linear Regression Algo(efficient) and set initial w = $w^T_{lin}$ to speed up the perceptron learning     </p>
<ul>
<li>誤差大小(看面積): Square Error &gt; 0/1 Error <img data-src="/img/ML/9-8.png"><ul>
<li>regression產生的 W 比 classification 的誤差更大，但計算時間較短 <img data-src="/img/ML/9-9.png"></li>
</ul>
</li>
</ul>
<h2 id="Chap-10-Logistic-Regression"><a href="#Chap-10-Logistic-Regression" class="headerlink" title="Chap 10 Logistic Regression"></a>Chap 10 Logistic Regression</h2><p>Heart attack prediction<br>Not every people with bad condition will have heart attack<br>→ only P(Heart attack | x) probability<br>→ look it as noise</p>
<p>若機率 P(+1|X) &gt; 1/2，則當成 +1，其他output當作noise <img data-src="/img/ML/10-1.png"></p>
<p>‘soft’ binary classification: f(x) = P(+1|x)</p>
<ul>
<li>ideal data: probabilty ↔ we have only noisy data(+1 or -1)</li>
<li><strong>the same data as perceptron, but different target function</strong></li>
</ul>
<h3 id="Logistic-Hypothesis"><a href="#Logistic-Hypothesis" class="headerlink" title="Logistic Hypothesis"></a>Logistic Hypothesis</h3><ul>
<li>smooth, monotonic, sigmoid(S形) function <img data-src="/img/ML/10-3.png"> <img data-src="/img/ML/10-2.png"><ul>
<li>0 &lt;= θ(x) &lt;= 1</li>
<li>θ(x) + θ(-x) = 1 </li>
<li>θ(-∞) = 0, θ(0) = 0.5, θ(∞) = 1</li>
<li>令 $h(x) = θ(w^Tx)$ <img data-src="/img/ML/10-4.png"></li>
</ul>
</li>
</ul>
<p>Likelihood<br>if h ~= f, [h 產生 y 的機率] 接近 [f 產生 y 的機率(其值通常大於產生其他output的機率)]<br>猜測：若能找到h, 其產生的output和f很像的話(也就是和data的output很像), 那h也會和f很像 → 成功學習<br>g = argmax_h likelihood(h) <img data-src="/img/ML/10-6.png"></p>
<h4 id="Cross-Entropy-Error"><a href="#Cross-Entropy-Error" class="headerlink" title="Cross-Entropy Error"></a>Cross-Entropy Error</h4><ul>
<li>因為 h(x) = θ(wTx)<ul>
<li>h(x) = h(-x)</li>
</ul>
</li>
<li>最高可能性 = max Π h(ynxn)<ul>
<li>Π = 連乘</li>
</ul>
</li>
<li>= max ln Π θ(ynwxn)<ul>
<li>轉換成θ，取ln</li>
</ul>
</li>
<li>= max Σ ln θ(ynwxn)<ul>
<li>ln Π = Σ ln</li>
</ul>
</li>
<li>= min 1/N x Σ -lnθ(ynwxn) <img data-src="/img/ML/10-7.png"><ul>
<li>乘1/N, 加上min和負號</li>
</ul>
</li>
<li>代入θ公式, Ein = <img data-src="/img/ML/10-8.png"><ul>
<li>此函式即為 Cross-Entropy Error <img data-src="/img/ML/10-9.png"></li>
</ul>
</li>
</ul>
<h4 id="Minimize-Cross-Entropy-Error"><a href="#Minimize-Cross-Entropy-Error" class="headerlink" title="Minimize Cross-Entropy Error"></a>Minimize Cross-Entropy Error</h4><p>find ∇Ein(w) = 0 to find min(Ein) <img data-src="/img/ML/10-11.png">  </p>
<ol>
<li>使所有θ項都為0<ul>
<li>only if all ynwxn &gt;&gt; 0</li>
<li>需要linear-seqerable data</li>
</ul>
</li>
<li>Σ(-ynxn) = 0<ul>
<li>non-linear equation of w</li>
</ul>
</li>
</ol>
<p>→ 都不好算 </p>
<p>solve it by PLA  </p>
<ul>
<li>若有錯則更新，正確則不變($w^t = w^{t+1}$) <img data-src="/img/ML/10-12.png"></li>
<li>加入參數η，為更新的幅度倍率(本來為1) <img data-src="/img/ML/10-13.png"><ul>
<li>v 代表原本的式子</li>
<li>用 (xn, yn) 更新的大小： $θ(-y_nw^Tx_n)$</li>
</ul>
</li>
</ul>
<h3 id="PLA-smoothing"><a href="#PLA-smoothing" class="headerlink" title="PLA smoothing"></a>PLA smoothing</h3><p><img data-src="/img/ML/10-14.png">   </p>
<ul>
<li>更新時就是在往Ein較低的方向走<ul>
<li>v為方向, η為幅度</li>
</ul>
</li>
<li>Greedy<ul>
<li>每次更新時調整η, 使Ein最小 <img data-src="/img/ML/10-17.png"><ul>
<li>η夠小的時候，可用泰勒展開式 <img data-src="/img/ML/10-15.png"></li>
<li>估算出的greedy更新公式 <img data-src="/img/ML/10-16.png"></li>
</ul>
</li>
</ul>
</li>
<li>Gradient Descent <img data-src="/img/ML/10-18.png">   <ul>
<li>最優的v是與梯度相反的方向，如果一條直線的斜率k&gt;0，說明向右是上升的方向，應該向左走 </li>
<li>距離谷底較遠（位置較高）時，步幅(η)大些比較好；接近谷底時，步幅小些比較好<ul>
<li>梯度的數值大小間接反映距離谷底的遠近 <img data-src="/img/ML/10-19.png"></li>
<li>希望步幅與梯度大小成正比<ul>
<li>wt+1 ← wt - η∇Ein(wt)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Update Time  </p>
<ul>
<li>decide wt+1 by all data → O(N) time</li>
<li>Can logistic regression with O(1) time per iteration(like PLA)?<br>→ use one of data instead of all data<br>→ <strong>Stochastic Gradient Descent</strong></li>
</ul>
<h4 id="Stochastic-Gradient-Descent-SGD"><a href="#Stochastic-Gradient-Descent-SGD" class="headerlink" title="Stochastic Gradient Descent (SGD)"></a>Stochastic Gradient Descent (SGD)</h4><p><img data-src="/img/ML/11-7.png" alt="stochastic gradient descent">      </p>
<ul>
<li>隨機選其中一筆資料來對 w 進行更新<ul>
<li>進行足夠多的更新後，平均的隨機梯度與平均的真實梯度近似相等</li>
</ul>
</li>
<li>η often use 0.1</li>
<li>compare PLA and SGD <img data-src="/img/ML/11-8.png"><ul>
<li>SGD is more flexible than PLA</li>
</ul>
</li>
</ul>
<h2 id="Chap-11-Linear-Models"><a href="#Chap-11-Linear-Models" class="headerlink" title="Chap 11 Linear Models"></a>Chap 11 Linear Models</h2><p>can linear regression or logistic regression help linear classification? </p>
<p><img data-src="/img/ML/11-1.png"><br><img data-src="/img/ML/11-2.png"> ys: classification correctness score</p>
<p>Error functions <img data-src="/img/ML/11-3.png">  </p>
<ul>
<li>small 0/1 error $\nRightarrow$ small square error</li>
<li>small err SQR → small err 0/1</li>
<li>small Err CE → small Err 0/1<ul>
<li>** small cross entropy error implies small classification error **<img data-src="/img/ML/11-4.png"> <img data-src="/img/ML/11-5.png"></li>
<li>small err SCE(scaled cross entropy) ↔ small err 0/1</li>
</ul>
</li>
</ul>
<p><img data-src="/img/ML/11-6.png">   </p>
<ol>
<li>PLA<ol>
<li>優點：在數據線性可分時高效且準確</li>
<li>缺點：只有在數據線性可分時才可行，否則需要借助POCKET算法（沒有理論保證）</li>
</ol>
</li>
<li>linear regression<ol>
<li>優點：最簡單的優化（直接利用矩陣運算工具）</li>
<li>缺點：ys 的值較大時，與 0/1 error 相差較大</li>
<li>線性回歸得到的結果w可作為其他算法的初始值</li>
</ol>
</li>
<li>logistic regression<ol>
<li>優點：比較容易優化（梯度下降）</li>
<li>缺點：ys 是非常小的負數時，與 0/1 error 相差較大</li>
<li>實際中，logistic回歸用於分類的效果優於線性回歸的方法和POCKET算法</li>
</ol>
</li>
</ol>
<h3 id="Multiclass-Classification-meta-algorithms"><a href="#Multiclass-Classification-meta-algorithms" class="headerlink" title="Multiclass Classification - meta algorithms"></a>Multiclass Classification - meta algorithms</h3><ol>
<li>One-Versus-All (OVA) Decomposition<ol>
<li>對每個分類做logistic regression(共N個)，選分數y最高的</li>
<li>優點：prediction有效率，學習時可平行處理</li>
<li>缺點：output種類很多時，數據往往非常不平衡(x 遠大於 o)，會嚴重影響訓練準確性</li>
<li><span class="exturl" data-url="aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTXVsdGlub21pYWxfbG9naXN0aWNfcmVncmVzc2lvbg==">multinomial logistic regression<i class="fa fa-external-link-alt"></i></span> 考慮了這個問題</li>
</ol>
</li>
<li>One versus One (OVO) <img data-src="/img/ML/11-9.png"><ol>
<li>共有 N(N-1)/2 個 perceptron，投票決定</li>
<li>優點： training有效率(每個perceptron較小), 可以使用 binary classification 的方法</li>
<li>缺點： O(K^2) space</li>
</ol>
</li>
</ol>
<h2 id="Chap-12-Nonlinear-Transformation"><a href="#Chap-12-Nonlinear-Transformation" class="headerlink" title="Chap 12 Nonlinear Transformation"></a>Chap 12 Nonlinear Transformation</h2><p>座標系轉換  </p>
<ul>
<li>將非線性的h(x)轉成線性 <ul>
<li>circular separable in X → linear separable in Z <img data-src="/img/ML/12-2.png">  <img data-src="/img/ML/12-1.png"> </li>
<li>可在X做出任何二次曲線的Z <img data-src="/img/ML/12-3.png"></li>
</ul>
</li>
<li>transform data X to Z to train easily <img data-src="/img/ML/12-4.png"><ul>
<li>(xn, yn) → (zn = ϕ(xn), yn)</li>
<li>train w by (z, y)</li>
<li>g(x) = sign(ϕ(x)w) (= sign(wz))</li>
</ul>
</li>
<li>代價<ul>
<li>O(Q^d)<ul>
<li>Q次方座標系, d個參數(x, y)</li>
</ul>
</li>
<li>$d_{vc}$ 隨 Q 成長</li>
</ul>
</li>
</ul>
<blockquote>
<p>力量愈強，代價愈大(可能會overfit)(見Chap13)</p>
</blockquote>
<p>有效學習的條件</p>
<ol>
<li>Ein(g) 約等於 Eout(g)</li>
<li>Ein(g)足夠小</li>
</ol>
<p>當模型很簡單時（dvc 很小），我們更容易滿足1. 而不容易滿足2. ；反之，模型很複雜時（dvc很大），更容易滿足2. 而不容易滿足1.<br>→ 次方愈高，hypothesis set 包含愈多、愈複雜，Eout更偏離，也對數據擬合得更充分，Ein 更小 <img data-src="/img/ML/12_1.png"> </p>
<p>安全的方法: 先算低次方, 若結果已足夠好就不用繼續尋找<br>實務上的機器學習，通常都不會使用太高維度的learning</p>
<blockquote>
<p>linear model first: simple, efficient, safe, and workable!</p>
</blockquote>
<p><span class="exturl" data-url="aHR0cDovL3poLndpa2lwZWRpYS5vcmcvemgtdHcvJUU1JThCJTkyJUU4JUFFJUE5JUU1JUJFJUI3JUU1JUE0JTlBJUU5JUExJUI5JUU1JUJDJThG">Legendre Polynomials Transform<i class="fa fa-external-link-alt"></i></span>: 互為正交的函式(?)，用來做transform效果較好</p>
<h2 id="Chap-13-Overfitting"><a href="#Chap-13-Overfitting" class="headerlink" title="Chap 13 Overfitting"></a>Chap 13 Overfitting</h2><p>overfitting: **lower Ein, higher Eout **<br><img data-src="/img/ML/13_01.png"><br>右側為overfitting, 左側為underfitting</p>
<h3 id="Case-Study"><a href="#Case-Study" class="headerlink" title="Case Study"></a>Case Study</h3><p>target function <img data-src="/img/ML/12_4.png"><br>try 2nd order and 10th order function <img data-src="/img/ML/12_5.png">     </p>
<ul>
<li>左側： H10 performance is not good even if original function is 10th-order</li>
<li>右側： even if no noise, there are still overfitting in H10<ul>
<li>hypothesis complexity acts like noise</li>
</ul>
</li>
<li>philosophy: 以退為進<ul>
<li>絕聖棄智，其效百倍，絕巧棄利，error無有</li>
</ul>
</li>
</ul>
<p>雖然H10在N大的時候Eout較低，但在N小的時候Eout非常大 <img data-src="/img/ML/12_6.png"><br>→ 資料不夠多(N小)的時候，不能用太複雜的hypothesis</p>
<p>實驗 noise 對 overfit 的影響  </p>
<ul>
<li>noise ε with variance σ^2<ul>
<li>normal distributed iid</li>
<li>red area has more overfit <img data-src="/img/ML/13_1.png"></li>
</ul>
</li>
<li>造成overfit的原因</li>
</ul>
<ol>
<li>deterministic noise<ol>
<li>最好的hypothesis和target function的差異(depends on H)</li>
<li>hypothesis complexity愈大，deterministic noise愈小</li>
</ol>
</li>
<li>stochastic noise<ol>
<li>N改變時，noise level對noise的影響  </li>
<li>不是固定值、不能改善</li>
<li>example: sample error</li>
</ol>
</li>
</ol>
<p>overfit的四個原因  </p>
<ol>
<li>data size ↓</li>
<li>stochastic noise ↑</li>
<li>deterministic noise ↑</li>
<li>hypothesis set的power ↑</li>
</ol>
<p>類比成開車 <img data-src="/img/ML/13-2.png"></p>
<p><strong>Overfit是很常發生的！</strong></p>
<p>Data Cleaning/Pruning:<br>對於有些”奇怪”的data   </p>
<ol>
<li>改成自己認為是對的output (data cleaning)</li>
<li>移除資料 (data pruning)</li>
</ol>
<p>Data Hinting:<br>用已有的知識處理原有的data，產生新的data(不是偷看！)，適合於資料量不足時(Ex. 手寫辨識，可稍微旋轉、平移)，要注意新data的比例是否符合現實情況</p>
<h2 id="Chap14-Regularization"><a href="#Chap14-Regularization" class="headerlink" title="Chap14 Regularization"></a>Chap14 Regularization</h2><p>Regularization： 設條件(constraint) 降低 hypothesis set 的 complexity</p>
<table>
<thead>
<tr>
<th>對H10改動(= H2’)</th>
<th>complexity</th>
</tr>
</thead>
<tbody><tr>
<td>w3~w10為0</td>
<td>H2’ == H2</td>
</tr>
<tr>
<td>w0~w10其中3個不為0</td>
<td>H2 &lt; H2’ &lt; H10</td>
</tr>
<tr>
<td>wi的和小於一固定值  H(C)=sum(w^2)&lt;=C</td>
<td>soft and smooth structure, e.g. H(0) &lt; H(11.26) &lt; H(∞) = H10</td>
</tr>
</tbody></table>
<p>限制參數大小： NP-hard to solve <img data-src="/img/ML/13-3.png"></p>
<p>Lagrange Multiplier <img data-src="/img/ML/13-4.png">   </p>
<ul>
<li>min(Ein)：朝梯度的反方向<ul>
<li>-▽Ein(W)為更新的向量</li>
</ul>
</li>
<li>W為原點到指定點的向量</li>
<li>只找出在紅色圓(限制)內的最佳解，即紅色圓上與$W_{lin}$最近的點<ul>
<li>$W_{lin}$為linear regression的解</li>
<li>W與-▽Ein(W)平行的時候 <img data-src="/img/ML/13-5.png"></li>
</ul>
</li>
</ul>
<p>可以藉由設不同的 λ 來產生 W，此時 λ 和 H(C) 的 C 相似，用來限制參數    </p>
<ul>
<li>Ridge Regression (similar to linear regression) <img data-src="/img/ML/13-6.png"></li>
<li>Augmented Error  <ul>
<li>solve min(Eaug) (unconstrained) is easier than solve min(Ein)(constrained) </li>
<li>積分後得到regularizer$w^Tw$ <img data-src="/img/ML/13-01.png"></li>
<li>wREG = argmin(w) Eaug(w)</li>
<li>weight-decay<ul>
<li>Penalize large weights using penalties</li>
<li>λ↑ → perfer shorter w → effective C↓</li>
</ul>
</li>
<li>λ 對應到 C <img data-src="/img/ML/13-9.png"></li>
</ul>
</li>
</ul>
<p>只需一點regularization就有效 <img data-src="/img/ML/13-8.png"> </p>
<p>regularizer只限制單一hypothesis的complexity，不像VC bound整個hypothesis set都限制，所以Eaug比Ein更接近Eout <img data-src="/img/ML/14-1.png"></p>
<p>Effective VC Dimension of Eaug  </p>
<ul>
<li>dVC(H) = d + 1 </li>
<li>實際的 dvc 更小(被λ限制)，但不好證明 <img data-src="/img/ML/14-2.png"></li>
</ul>
<p>General Regularizers <img data-src="/img/ML/14-3.png">    </p>
<ul>
<li>target-dependent<ul>
<li>用target function的性質來限制</li>
</ul>
</li>
<li>plausible(合理的)<ul>
<li>預期比較平滑、簡單的hypothesis，因為noise是較不平滑的</li>
<li>L1(sparsity regularizer): regularizer = Σ|wq|</li>
</ul>
</li>
<li>friendly(easy to use)<ul>
<li>L2(weight-decay regularizer): regularizer = Σ$w_q^2$</li>
</ul>
</li>
<li>comparison: error → user-dependent, plausible, friendly</li>
<li>augmented error = error + regulizer</li>
</ul>
<p><img data-src="/img/ML/14-4.png" alt="L1 and L2"> L1 useful when need sparse solution(有許多零的w, 因w最終會落到正方形的頂點)，L1即表示限制函數為一次方 </p>
<p>noise愈多，需要的regularization愈多 ↔ more bumpy road, putting brakes more <img data-src="/img/ML/14-5.png"></p>
<p>Conclusion:<br>正規化用來減少hypothesis的complexity，避免overfit，用wTw作regulizer(L2)，以λ為參數調整正規化的程度(即L2圓的大小，L1正方形的大小)，通常λ不會太大</p>
<h2 id="Chap15-Validation"><a href="#Chap15-Validation" class="headerlink" title="Chap15 Validation"></a>Chap15 Validation</h2><p>So Many Models can choose, so use validation to check which is good choice</p>
<p>selecting by E_in is dangerous(can’t reflect Eout)<br>selecting by E_test is infeasible and cheating(not easy to get test data)</p>
<p>$E_{val}$: legal cheating     </p>
<ul>
<li>將data分成train和validation二部分</li>
<li>用train學習，用valid測試</li>
</ul>
<p>在許多切割(fold)之中，找$E_{val}$最小的hypothesis，並用這個hypothesis和<strong>全部的data</strong>算出g <img data-src="/img/ML/15-1.png">   </p>
<ul>
<li>$g_m^{-}$ 為 validation data 算出的g <img data-src="/img/ML/14-7.png"> </li>
<li>find balance of validation data size <img data-src="/img/ML/15-2.png"><ul>
<li>leave-one-out cross validation ($E_{loocv}$)<ul>
<li>每次只用一個資料作validation(K = 1)</li>
<li>often called ‘almost unbiased estimate of Eout’ <img data-src="/img/ML/15-3.png">  </li>
<li>缺點：計算太多(一個model要train N次, N為資料個數)</li>
<li>改善：切成n塊(通常5fold, 10fold)</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>選擇 - 先選要測試的models，再用validation選出最好的     </p>
<ol>
<li>all training models: select among hypotheses(初賽)</li>
<li>all validation schemes: select among finalists(複賽)</li>
<li>all testing methods: just evaluate</li>
<li>Still use <strong>test result(之前沒用過的data)</strong> for final benchmark, not best validation result</li>
</ol>
<h2 id="Chap16-Three-Learning-Principles"><a href="#Chap16-Three-Learning-Principles" class="headerlink" title="Chap16 Three Learning Principles"></a>Chap16 Three Learning Principles</h2><h3 id="Occam’s-Razor"><a href="#Occam’s-Razor" class="headerlink" title="Occam’s Razor"></a>Occam’s Razor</h3><p>An explanation of the data should be made as simple as possible, but no simpler<br>用最簡單且有效的方法解釋資料<br><img data-src="/img/ML/16-1.png"><br>因為愈簡單的H 愈難分資料 → 可以分開資料時，有顯著性(若是用複雜模型，分開是很容易的)<br>→ linear first, always ask whether overfitting</p>
<h3 id="Sampling-Bias"><a href="#Sampling-Bias" class="headerlink" title="Sampling Bias"></a>Sampling Bias</h3><p>抽樣誤差：抽樣非真正隨機<br>Ex. 1948電話民調，但電話當時昂貴<br>movie recommend system: When data have time sequential, should emphasize later data, do not use random data</p>
<h3 id="Data-Snooping"><a href="#Data-Snooping" class="headerlink" title="Data Snooping"></a>Data Snooping</h3><p>偷看資料(機器學習 → 人腦學習)，會包含大腦所花的complexity <img data-src="/img/ML/16-2.png"> <img data-src="/img/ML/16-3.png"> </p>
<p>paper1: H1 works well on data D<br>paper2: find H2 and <strong>publish if better than H1 on D</strong><br>….<br>→ bad generalization, cause overfit (if you torture the data long enough, it will confess)<br>→ 解決方法：不要先看paper，先提出自己的方法，再和已發表的方法比較</p>
<h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>Three Related Fields<br><img data-src="/img/ML/16-4.png"><br>Three Theoretical Bounds<br><img data-src="/img/ML/16-5.png"><br>Three Linear Models<br><img data-src="/img/ML/16-6.png"><br>Three Key Tools: Feature Transform, Regularization, Validation<br><img data-src="/img/ML/16-7.png"><br>Three Future Directions(in <a href="http://gitqwerty777.github.io/MLtechnique/">ML techniques</a>)<br><img data-src="/img/ML/16-8.png">  </p>
<p>End~~</p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><span class="exturl" data-url="aHR0cDovL3d3dy5kb3ViYW4uY29tL2RvdWxpc3QvMzM4MTg1My8=">http://www.douban.com/doulist/3381853/<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cDovL3d3dy5jc2llLm50dS5lZHUudHcvfmh0bGluL2NvdXJzZS9tbDE0ZmFsbC8=">HTLin講義<i class="fa fa-external-link-alt"></i></span><br><span class="exturl" data-url="aHR0cHM6Ly9jbGFzcy5jb3Vyc2VyYS5vcmcvbnR1bWxvbmUtMDAy">Coursera<i class="fa fa-external-link-alt"></i></span></p>

    </div>

    
    
    
      
  <div class="popular-posts-header">相關文章</div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/MLfoundation1/" rel="bookmark">機器學習基石(上)</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/MLtechnique/" rel="bookmark">機器學習技法</a></div>
    </li>
    <li class="popular-posts-item">
      <div class="popular-posts-title"><a href="/Emacs-introduction/" rel="bookmark">Emacs觀念</a></div>
    </li>
  </ul>

        

  <div class="followme">
    <p>歡迎關注我的其它發布管道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/atom.xml">
            <span class="icon">
              <i class="fa fa-rss"></i>
            </span>

            <span class="label">RSS</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          
          <div class="post-tags">
              <a href="/tags/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/" rel="tag"><i class="fa fa-tag"></i> 機器學習</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/computer-gaming/" rel="prev" title="電腦對局理論">
      <i class="fa fa-chevron-left"></i> 電腦對局理論
    </a></div>
      <div class="post-nav-item">
    <a href="/MLtechnique/" rel="next" title="機器學習技法">
      機器學習技法 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    
  <div class="comments">
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap09-Linear-Regression"><span class="nav-number">1.</span> <span class="nav-text">Chap09 Linear Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#linear-regression-algorithm-easy"><span class="nav-number">1.1.</span> <span class="nav-text">linear regression algorithm(easy)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E2%80%9CSimpler-than-VC%E2%80%9D-Guarantee"><span class="nav-number">1.2.</span> <span class="nav-text">“Simpler-than-VC” Guarantee</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Hat-Matrix-in-Geometry"><span class="nav-number">1.2.1.</span> <span class="nav-text">Hat Matrix in Geometry</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Usage"><span class="nav-number">1.3.</span> <span class="nav-text">Usage</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap-10-Logistic-Regression"><span class="nav-number">2.</span> <span class="nav-text">Chap 10 Logistic Regression</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Logistic-Hypothesis"><span class="nav-number">2.1.</span> <span class="nav-text">Logistic Hypothesis</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Cross-Entropy-Error"><span class="nav-number">2.1.1.</span> <span class="nav-text">Cross-Entropy Error</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Minimize-Cross-Entropy-Error"><span class="nav-number">2.1.2.</span> <span class="nav-text">Minimize Cross-Entropy Error</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PLA-smoothing"><span class="nav-number">2.2.</span> <span class="nav-text">PLA smoothing</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Stochastic-Gradient-Descent-SGD"><span class="nav-number">2.2.1.</span> <span class="nav-text">Stochastic Gradient Descent (SGD)</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap-11-Linear-Models"><span class="nav-number">3.</span> <span class="nav-text">Chap 11 Linear Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Multiclass-Classification-meta-algorithms"><span class="nav-number">3.1.</span> <span class="nav-text">Multiclass Classification - meta algorithms</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap-12-Nonlinear-Transformation"><span class="nav-number">4.</span> <span class="nav-text">Chap 12 Nonlinear Transformation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap-13-Overfitting"><span class="nav-number">5.</span> <span class="nav-text">Chap 13 Overfitting</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Case-Study"><span class="nav-number">5.1.</span> <span class="nav-text">Case Study</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap14-Regularization"><span class="nav-number">6.</span> <span class="nav-text">Chap14 Regularization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap15-Validation"><span class="nav-number">7.</span> <span class="nav-text">Chap15 Validation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap16-Three-Learning-Principles"><span class="nav-number">8.</span> <span class="nav-text">Chap16 Three Learning Principles</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Occam%E2%80%99s-Razor"><span class="nav-number">8.1.</span> <span class="nav-text">Occam’s Razor</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sampling-Bias"><span class="nav-number">8.2.</span> <span class="nav-text">Sampling Bias</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Data-Snooping"><span class="nav-number">8.3.</span> <span class="nav-text">Data Snooping</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conclusion"><span class="nav-number">8.4.</span> <span class="nav-text">Conclusion</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Reference"><span class="nav-number">9.</span> <span class="nav-text">Reference</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="qwerty" src="/img/qwerty.png">
  <p class="site-author-name" itemprop="name">qwerty</p>
  <div class="site-description" itemprop="description">Programming | Computer Science | Thought</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">59</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">143</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cDovL2dpdGh1Yi5jb20vZ2l0cXdlcnR5Nzc3" title="GitHub → http://github.com/gitqwerty777"><i class="fab fa-github fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOmdvb2hjbDc3N0BnbWFpbC5jb20=" title="E-Mail → mailto:goohcl777@gmail.com"><i class="fa fa-envelope fa-fw"></i></span>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC96aC10dw=="><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></span>
  </div>


  <div class="links-of-blogroll motion-element">
    <div class="links-of-blogroll-title"><i class="fa fa-link fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9xd2VydHk3NzcubWU=" title="https://qwerty777.me">My Main Page</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cDovL3F3ZXJ0eTc3Ny5tZS9saWZlLw==" title="http://qwerty777.me/life/">My Second Blog -- wysiwyg</span>
        </li>
    </ul>
  </div>

      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  © 2014 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fab fa-free-code-camp"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">qwerty</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-area"></i>
    </span>
      <span class="post-meta-item-text">總字數：</span>
    <span title="總字數">457k</span>
</div>
  <div class="powered-by">由 <span class="exturl theme-link" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> &amp; <span class="exturl theme-link" data-url="aHR0cHM6Ly9waXNjZXMudGhlbWUtbmV4dC5vcmc=">NexT.Pisces</span> 強力驅動
  </div>
  <div class="addthis_inline_share_toolbox">
    <script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-61c5cf9cb3476405" async="async"></script>
  </div>

        








      </div>
    </footer>
  </div>

  
  
  
  <script src="//cdn.jsdelivr.net/npm/medium-zoom@1/dist/medium-zoom.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/lozad@1/dist/lozad.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/pangu@4/dist/browser/pangu.min.js"></script>
  
  











  




  
  




  















    <div id="pjax">
  

  
      



    

  



    </div>


<script src="/bundle.js"></script><script>var pjax = new Pjax({
  selectors: [
    'head title',
    '#page-configurations',
    '.content-wrap',
    '.post-toc-wrap',
    '.languages',
    '#pjax'
  ],
  switches: {
    '.post-toc-wrap': Pjax.switches.innerHTML
  },
  analytics: false,
  cacheBust: false,
  scrollTo : !CONFIG.bookmark.enable
});

window.addEventListener('pjax:success', () => {
  document.querySelectorAll('script[data-pjax], script#page-configurations, #pjax script').forEach(element => {
    var code = element.text || element.textContent || element.innerHTML || '';
    var parent = element.parentNode;
    parent.removeChild(element);
    var script = document.createElement('script');
    if (element.id) {
      script.id = element.id;
    }
    if (element.className) {
      script.className = element.className;
    }
    if (element.type) {
      script.type = element.type;
    }
    if (element.src) {
      script.src = element.src;
      // Force synchronous loading of peripheral JS.
      script.async = false;
    }
    if (element.dataset.pjax !== undefined) {
      script.dataset.pjax = '';
    }
    if (code !== '') {
      script.appendChild(document.createTextNode(code));
    }
    parent.appendChild(script);
  });
  NexT.boot.refresh();
  // Define Motion Sequence & Bootstrap Motion.
  if (CONFIG.motion.enable) {
    NexT.motion.integrator
      .init()
      .add(NexT.motion.middleWares.subMenu)
      .add(NexT.motion.middleWares.postList)
      .bootstrap();
  }
  NexT.utils.updateSidebarPosition();
});;(function(){
      var canonicalURL, curProtocol;
      //Get the <link> tag
      var x=document.getElementsByTagName("link");
		//Find the last canonical URL
		if(x.length > 0){
			for (i=0;i<x.length;i++){
				if(x[i].rel.toLowerCase() == 'canonical' && x[i].href){
					canonicalURL=x[i].href;
				}
			}
		}
    //Get protocol
	    if (!canonicalURL){
	    	curProtocol = window.location.protocol.split(':')[0];
	    }
	    else{
	    	curProtocol = canonicalURL.split(':')[0];
	    }
      //Get current URL if the canonical URL does not exist
	    if (!canonicalURL) canonicalURL = window.location.href;
	    //Assign script content. Replace current URL with the canonical URL
      !function(){var e=/([http|https]:\/\/[a-zA-Z0-9\_\.]+\.baidu\.com)/gi,r=canonicalURL,t=document.referrer;if(!e.test(r)){var n=(String(curProtocol).toLowerCase() === 'https')?"https://sp0.baidu.com/9_Q4simg2RQJ8t7jm9iCKT-xh_/s.gif":"//api.share.baidu.com/s.gif";t?(n+="?r="+encodeURIComponent(document.referrer),r&&(n+="&l="+r)):r&&(n+="?l="+r);var i=new Image;i.src=n}}(window);})();;if (document.querySelectorAll('pre.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8/dist/mermaid.min.js', () => {
    mermaid.initialize({
      theme    : 'forest',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    });
  }, window.mermaid);
};if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
          load: ['[tex]/mhchem'],
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
          packages: {'[+]': ['mhchem']},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  };var disqus_config = function() {
    this.page.url = "http://gitqwerty777.github.io/MLfoundation2/";
    this.page.identifier = "MLfoundation2/";
    this.page.title = "機器學習基石(下)";
    };
  NexT.utils.loadComments(document.querySelector('#disqus_thread'), () => {
    if (window.DISQUS) {
      DISQUS.reset({
        reload: true,
        config: disqus_config
      });
    } else {
      var d = document, s = d.createElement('script');
      s.src = 'https://disqusforqwerty.disqus.com/embed.js';
      s.setAttribute('data-timestamp', '' + +new Date());
      (d.head || d.body).appendChild(s);
    }
  });</script></body></html>