<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>http://gitqwerty777.github.io</id>
    <title>QWERTY • Posts by &#34;wideanddeep&#34; tag</title>
    <link href="http://gitqwerty777.github.io" />
    <updated>2021-12-20T07:18:44.000Z</updated>
    <category term="C#" />
    <category term="CodingStyle" />
    <category term="Emacs" />
    <category term="編輯器" />
    <category term="CFR" />
    <category term="電腦對局理論" />
    <category term="指令" />
    <category term="機器學習" />
    <category term="perceptron" />
    <category term="readme" />
    <category term="文件" />
    <category term="github" />
    <category term="artificial intelligence" />
    <category term="search" />
    <category term="First-Order Logic" />
    <category term="大數" />
    <category term="程式" />
    <category term="C++" />
    <category term="Hexo" />
    <category term="網誌" />
    <category term="Markdown" />
    <category term="CleanCode" />
    <category term="重構" />
    <category term="TDD" />
    <category term="設計模式" />
    <category term="CMake" />
    <category term="Makefile" />
    <category term="Linux" />
    <category term="Todo" />
    <category term="註解" />
    <category term="經濟學" />
    <category term="策略" />
    <category term="競爭" />
    <category term="博弈論" />
    <category term="計算機結構" />
    <category term="人工智慧" />
    <category term="圍棋" />
    <category term="象棋" />
    <category term="蒙地卡羅" />
    <category term="Alpha-Beta搜尋" />
    <category term="強化學習" />
    <category term="計算機網路" />
    <category term="boost" />
    <category term="函式庫" />
    <category term="編譯" />
    <category term="gcc" />
    <category term="g++" />
    <category term="clang" />
    <category term="最佳化" />
    <category term="推薦系統" />
    <category term="FM" />
    <category term="FFM" />
    <category term="SVM" />
    <category term="Embedding" />
    <category term="自然語言處理" />
    <category term="外國用語" />
    <category term="萌典" />
    <category term="opencc" />
    <category term="PTT" />
    <category term="vuejs" />
    <category term="linux" />
    <category term="c" />
    <category term="compile" />
    <category term="gdb" />
    <category term="c語言" />
    <category term="cpp" />
    <category term="除錯" />
    <category term="git" />
    <category term="VMWare" />
    <category term="虛擬機" />
    <category term="IFTTT" />
    <category term="自動化" />
    <category term="備份" />
    <category term="webhook" />
    <category term="簡報" />
    <category term="軟體" />
    <category term="PowerPoint" />
    <category term="Latex" />
    <category term="JavaScript" />
    <category term="CSS" />
    <category term="Unity" />
    <category term="fcitx" />
    <category term="嘸蝦米" />
    <category term="輸入法" />
    <category term="硬碟" />
    <category term="記憶體" />
    <category term="效能" />
    <category term="錯誤" />
    <category term="makefile" />
    <category term="備忘錄" />
    <category term="存檔" />
    <category term="統計" />
    <category term="byobu" />
    <category term="screen" />
    <category term="tmux" />
    <category term="reactjs" />
    <category term="javascript" />
    <category term="WideAndDeep" />
    <category term="Google" />
    <category term="觀察者" />
    <category term="訂閱" />
    <category term="委託" />
    <category term="正規表示式(RegExp)" />
    <category term="上下文無關文法(CFG)" />
    <category term="hexo" />
    <category term="blog" />
    <category term="theme" />
    <category term="feature" />
    <category term="revealJS" />
    <category term="markdown" />
    <category term="rss" />
    <category term="facebook" />
    <category term="youtube" />
    <category term="ptt" />
    <category term="bilibili" />
    <category term="pixiv" />
    <category term="crawler" />
    <category term="SEO" />
    <category term="google" />
    <category term="html" />
    <category term="amazon" />
    <category term="webhost" />
    <category term="ssl" />
    <category term="漢字" />
    <category term="中文" />
    <category term="異體字" />
    <category term="unicode" />
    <category term="unity" />
    <category term="演算法" />
    <category term="隨機排序" />
    <category term="洗牌" />
    <category term="Fisher-Yates" />
    <category term="證明" />
    <category term="python" />
    <entry>
        <id>http://gitqwerty777.github.io/recommender-wide-and-deep/</id>
        <title>Wide And Deep 論文簡介：快思慢想的神經網路版</title>
        <link rel="alternate" href="http://gitqwerty777.github.io/recommender-wide-and-deep/"/>
        <content type="html">&lt;h2 id=&#34;簡介&#34;&gt;&lt;a href=&#34;#簡介&#34; class=&#34;headerlink&#34; title=&#34;簡介&#34;&gt;&lt;/a&gt;簡介&lt;/h2&gt;&lt;p&gt;Wide And Deep 模型由簡單的Wide模型和複雜的Deep模型組成&lt;/p&gt;
&lt;a id=&#34;more&#34;&gt;&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Wide&lt;ul&gt;
&lt;li&gt;Memorization(記憶)&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Generalized linear model&lt;/strong&gt;(e.g., Linear Regression Model)&lt;/li&gt;
&lt;li&gt;適合學習稀疏、簡單的規則&lt;ul&gt;
&lt;li&gt;看了 A 電影的使用者經常喜歡看電影 B，這種「因為 A 所以 B」式的規則&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;從歷史資料學習規則(exploit)&lt;/li&gt;
&lt;li&gt;讓模型記住大量的直接且重要的規則，這正是單層的線性模型所擅長的&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Deep&lt;ul&gt;
&lt;li&gt;Generalization(泛化)&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Embedding-based models&lt;/strong&gt;(e.g., Deep Neural Network)&lt;/li&gt;
&lt;li&gt;適合學習通用、深層的規則&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;學習新的特徵組合(explore)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;合併 Wide and Deep(Jointly Training) &lt;img data-src=&#34;/img/recommend/wide-and-deep.png&#34; alt=&#34;&#34;&gt;&lt;ul&gt;
&lt;li&gt;既能快速處理和記憶大量歷史行為特徵，又具有強大的表達能力&lt;/li&gt;
&lt;li&gt;和 Deep-only 比: 準確率高&lt;/li&gt;
&lt;li&gt;和 Wide-only 比: 更好的泛化規則&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;當user-item matrix非常稀疏時，例如有獨特愛好的users以及很小眾的items，NN很難為users和items學習到有效的embedding。導致over-generalize，並推薦不怎麼相關的物品。此時Memorization就展示了優勢，它可以「記住」這些特殊的特徵組合&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;實作&#34;&gt;&lt;a href=&#34;#實作&#34; class=&#34;headerlink&#34; title=&#34;實作&#34;&gt;&lt;/a&gt;實作&lt;/h2&gt;&lt;h3 id=&#34;Wide&#34;&gt;&lt;a href=&#34;#Wide&#34; class=&#34;headerlink&#34; title=&#34;Wide&#34;&gt;&lt;/a&gt;Wide&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;$y = w^Tx+b$&lt;/li&gt;
&lt;li&gt;Cross product transformation&lt;ul&gt;
&lt;li&gt;&lt;img data-src=&#34;/img/recommend/wide-and-deep-cross-product.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimizer: Follow-the-regularized-leader (FTRL) + L1 regularization&lt;ul&gt;
&lt;li&gt;FTRL with L1非常注重模型的稀疏性。採用L1 FTRL是想讓Wide部分變得更加稀疏&lt;ul&gt;
&lt;li&gt;但是兩個id類特徵向量進行組合，在維度爆炸的同時，會讓原本已經非常稀疏的multihot特徵向量，變得更加稀疏。正因如此，wide部分的權重數量其實是海量的。為了不把數量如此之巨的權重都搬到線上進行model serving，採用FTRL過濾掉哪些稀疏特徵無疑是非常好的工程經驗&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Wide的輸入特徵較少&lt;ul&gt;
&lt;li&gt;只有已安裝app和瀏覽過的app&lt;/li&gt;
&lt;li&gt;希望能充份發揮Wide記憶能力強的優勢&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;Deep&#34;&gt;&lt;a href=&#34;#Deep&#34; class=&#34;headerlink&#34; title=&#34;Deep&#34;&gt;&lt;/a&gt;Deep&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;特徵(節錄)&lt;ul&gt;
&lt;li&gt;用戶特徵&lt;ul&gt;
&lt;li&gt;年齡、國家、語言&lt;/li&gt;
&lt;li&gt;行為特徵&lt;ul&gt;
&lt;li&gt;已安裝App個數&lt;/li&gt;
&lt;li&gt;已安裝的App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;情境特徵&lt;ul&gt;
&lt;li&gt;使用裝置&lt;/li&gt;
&lt;li&gt;目前時間(星期，小時)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;App特徵&lt;ul&gt;
&lt;li&gt;發佈時間&lt;/li&gt;
&lt;li&gt;下載數&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;候選App&lt;/li&gt;
&lt;li&gt;部份特徵有做embedding(Wide完全沒有)&lt;ul&gt;
&lt;li&gt;32 dimension&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Optimizer: AdaGrad&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;Jointly-Training&#34;&gt;&lt;a href=&#34;#Jointly-Training&#34; class=&#34;headerlink&#34; title=&#34;Jointly Training&#34;&gt;&lt;/a&gt;Jointly Training&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;同時更新Wide和Deep的權重&lt;ul&gt;
&lt;li&gt;&lt;img data-src=&#34;/img/recommend/wide-and-deep-joint-train.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;結構圖&lt;ul&gt;
&lt;li&gt;&lt;img data-src=&#34;/img/recommend/wide-and-deep-features.png&#34; alt=&#34;&#34;&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;結果&#34;&gt;&lt;a href=&#34;#結果&#34; class=&#34;headerlink&#34; title=&#34;結果&#34;&gt;&lt;/a&gt;結果&lt;/h2&gt;&lt;p&gt;實際用在 Google Play Store App 推薦&lt;/p&gt;
&lt;p&gt;&lt;img data-src=&#34;/img/recommend/wide-and-deep-exp.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Deep雖然離線結果較差，但實際結果仍比Wide好&lt;ul&gt;
&lt;li&gt;深層模型有學習到使用者的隱含喜好，而非直接記憶規則&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;心得&#34;&gt;&lt;a href=&#34;#心得&#34; class=&#34;headerlink&#34; title=&#34;心得&#34;&gt;&lt;/a&gt;心得&lt;/h2&gt;&lt;p&gt;這就是&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly93d3cubWFuYWdlcnRvZGF5LmNvbS50dy9hcnRpY2xlcy92aWV3LzUwOTA1Pw==&#34;&gt;快思慢想&lt;i class=&#34;fa fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/span&gt;的神經網路版&lt;/p&gt;
&lt;p&gt;Wide處理簡單的規則且省力，Deep處理複雜的規則但費力&lt;/p&gt;
&lt;p&gt;和純粹的deep learning相比，適合需要記憶大量簡易規則的情境。如App推薦中，有安裝A就推薦B&lt;/p&gt;
&lt;p&gt;Wide and Deep是一個架構，Wide模型和Deep模型可以為任意實作，所以衍生出許多變形，如DeepFM, Deep and Cross等&lt;/p&gt;
&lt;!--
deep的效率跟不上，可以固定住deep，對wide進行online learning來增強記憶性。
非常贊 跟我們的討論結果基本一致，deep部分做batch update保證准確性和充足表達能力，wide部分做online learning保證實效性。

用戶-物品互動太少 → over-generalize
wide部分的引入是為瞭解決 niche items的問題，對於很長尾的物品，dense features是沒法學到什麼東西的

However,deep neural networks with embeddings can over-generalize
and recommend less relevant items when the user-item inter-
actions are sparse and high-rank.
當user-item matrix非常稀疏時，例如有和獨特愛好的users以及很小眾的items，NN很難為users和items學習到有效的embedding。這種情況下，大部分user-item應該是沒有關聯的，但dense embedding 的方法還是可以得到對所有 user-item pair 的非零預測，因此導致 over-generalize並推薦不怎麼相關的物品。此時Memorization就展示了優勢，它可以“記住”這些特殊的特徵組合。
https://en.wikipedia.org/wiki/Rank_(linear_algebra)
--&gt;

&lt;h2 id=&#34;Reference&#34;&gt;&lt;a href=&#34;#Reference&#34; class=&#34;headerlink&#34; title=&#34;Reference&#34;&gt;&lt;/a&gt;Reference&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9hcnhpdi5vcmcvYWJzLzE2MDYuMDc3OTI=&#34;&gt;Cheng, Heng-Tze, et al. “Wide &amp;amp; deep learning for recommender systems.” Proceedings of the 1st workshop on deep learning for recommender systems. 2016.&lt;i class=&#34;fa fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly9tZWRpdW0uY29tL2RhdGEtc2NpZW50aXN0cy1wbGF5Z3JvdW5kL3dpZGUtZGVlcCVFNiVBOCVBMSVFNSU5RSU4Qi0lRTYlOEUlQTglRTglOTYlQTYlRTclQjMlQkIlRTclQjUlQjEtJUU1JThFJTlGJUU3JTkwJTg2LThiYWRhY2Y3NzdmMw==&#34;&gt;https://medium.com/data-scientists-playground/wide-deep%E6%A8%A1%E5%9E%8B-%E6%8E%A8%E8%96%A6%E7%B3%BB%E7%B5%B1-%E5%8E%9F%E7%90%86-8badacf777f3&lt;i class=&#34;fa fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC8xNDI5NTg4MzQ=&#34;&gt;https://zhuanlan.zhihu.com/p/142958834&lt;i class=&#34;fa fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;span class=&#34;exturl&#34; data-url=&#34;aHR0cHM6Ly96aHVhbmxhbi56aGlodS5jb20vcC81MzM2MTUxOQ==&#34;&gt;https://zhuanlan.zhihu.com/p/53361519&lt;i class=&#34;fa fa-external-link-alt&#34;&gt;&lt;/i&gt;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
        <category term="推薦系統" />
        <category term="WideAndDeep" />
        <category term="Google" />
        <updated>2021-12-20T07:18:44.000Z</updated>
    </entry>
</feed>
