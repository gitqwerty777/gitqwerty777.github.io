{
    "version": "https://jsonfeed.org/version/1",
    "title": "QWERTY • All posts by \"alpha-beta搜尋\" tag",
    "description": "Programming | Computer Science | Thought",
    "home_page_url": "http://gitqwerty777.github.io",
    "items": [
        {
            "id": "http://gitqwerty777.github.io/computer-gaming/",
            "url": "http://gitqwerty777.github.io/computer-gaming/",
            "title": "電腦對局理論",
            "date_published": "2014-09-26T11:41:48.000Z",
            "content_html": "<!-- RENEW: -->\n\n<blockquote>\n<p>註：此為2014年版，且只寫到第八章(因為教授只考到這)</p>\n</blockquote>\n<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h3 id=\"學習電腦對局的用處\"><a href=\"#學習電腦對局的用處\" class=\"headerlink\" title=\"學習電腦對局的用處\"></a>學習電腦對局的用處</h3><ol>\n<li>電腦愈聰明，對人類愈有用</li>\n<li>電腦學得的技巧讓人學習</li>\n</ol>\n<h3 id=\"為何學棋局\"><a href=\"#為何學棋局\" class=\"headerlink\" title=\"為何學棋局\"></a>為何學棋局</h3><ol>\n<li>容易辨別輸贏</li>\n<li>規則簡單(先備知識少)</li>\n</ol>\n<a id=\"more\"></a>\n\n<h3 id=\"圖靈測試-Turing-test\"><a href=\"#圖靈測試-Turing-test\" class=\"headerlink\" title=\"圖靈測試(Turing test)\"></a>圖靈測試(Turing test)</h3><p>If a machine is intelligent, then it cannot be distinguished from a human</p>\n<ul>\n<li>反過來利用的例子 - CAPTCHA(驗證碼): Completely Automated Public Turing test to tell Computers and Humans Apart</li>\n<li>Wolfram Alpha<ul>\n<li>knowledge base of Siri</li>\n</ul>\n</li>\n</ul>\n<p>Problems  </p>\n<ul>\n<li>Are all human behaviors intelligent?</li>\n<li>Can human perform every possible intelligent behavior?<br>→ Human Intelligence 和 Intelligence 並不完全相同</li>\n</ul>\n<h3 id=\"改變目標\"><a href=\"#改變目標\" class=\"headerlink\" title=\"改變目標\"></a>改變目標</h3><ul>\n<li>From Artificial Intelligence to <strong>Machine Intelligence</strong><ul>\n<li>machine intelligence: the thing machine can do better than human do</li>\n</ul>\n</li>\n<li>From imitation of human behaviors to doing intelligent behaviors</li>\n<li>From general-purpose intelligence to <strong>domain-dependent</strong> Expert Systems</li>\n</ul>\n<h3 id=\"重大突破\"><a href=\"#重大突破\" class=\"headerlink\" title=\"重大突破\"></a>重大突破</h3><ul>\n<li>1912 - End-Game chess playing machine  </li>\n<li>~1970 - Brute Force    </li>\n<li>1975 - Alpha-Beta pruning(Knuth and Moore)   </li>\n<li>1993 - Monte Carlo  </li>\n</ul>\n<h3 id=\"無關：核心知識\"><a href=\"#無關：核心知識\" class=\"headerlink\" title=\"無關：核心知識\"></a>無關：核心知識</h3><p>用少部分的核心知識(要記得的事物)推得大多數的知識<br>Ex. 背九九乘法表推得所有多位數乘法<br>建構式數學(X)  </p>\n<h3 id=\"對局分類\"><a href=\"#對局分類\" class=\"headerlink\" title=\"對局分類\"></a>對局分類</h3><p><strong>研究遊戲之前的必要分析：分類</strong></p>\n<p>By number of players   </p>\n<ul>\n<li>Single-player games<ul>\n<li>puzzles</li>\n<li>Most of them are NP-complete<ul>\n<li>or the game will be not fun to play</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Two-player games<ul>\n<li>Most of them are either P-SPACE-complete(polynomial space usage) or exponential-time-complete<ul>\n<li>PSPACE-complete can be thought of as the hardest problems in PSPACE, solution of PSPACE-complete could easily be used to solve any other problem in PSPACE</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Multi-player games</li>\n</ul>\n<p>By state information obtained by each player(盤面資訊是否完全)  </p>\n<ul>\n<li>Perfect-information games<ul>\n<li>all players have all the information to make a correct decision</li>\n</ul>\n</li>\n<li>Imperfect-information games<ul>\n<li>some information is only available to selected players, for example you cannot see the opponent’s cards in Poker(不知對手的牌或棋子, Ex. 橋牌)</li>\n</ul>\n</li>\n</ul>\n<p>By rules of games known in advance(是否有特殊規則、是否知道對手的行動)  </p>\n<ul>\n<li>Complete-information games<ul>\n<li>rules of the game are fully known by all players in advance</li>\n</ul>\n</li>\n<li>Incomplete-information games<ul>\n<li>partial rules are not given in advance for some players(Ex. 囚犯困境賽局)</li>\n</ul>\n</li>\n</ul>\n<p><span class=\"exturl\" data-url=\"aHR0cDovL3d3dy5lY29uLnVjc2IuZWR1L35nYXJyYXR0L0Vjb24xNzEvTGVjdDE0X1NsaWRlcy5wZGY=\">definition of perfect and complete information in game theory<i class=\"fa fa-external-link-alt\"></i></span></p>\n<p>By whether players can fully control the playing of the game(是否受隨機性影響)    </p>\n<ul>\n<li>Stochastic games<ul>\n<li>there is an element of chance such as dice rolls </li>\n</ul>\n</li>\n<li>Deterministic games<ul>\n<li>players have a full control over the games</li>\n</ul>\n</li>\n</ul>\n<p>Example(not fully sure):  </p>\n<ul>\n<li>perfect-information complete-information deterministic game: chinese chess, go    </li>\n<li>perfect-information complete-information stochastic game: dark chinese chess, 輪盤(Roulette)    </li>\n<li>perfect-information incomplete-information deterministic game: Prisoner’s Dilemma    </li>\n<li>perfect-information incomplete-information stochastic game: ?    </li>\n<li>inperfect-information complete-information deterministic game: ?    </li>\n<li>inperfect-information complete-information stochastic game: monopoly, bridge   </li>\n<li>inperfect-information incomplete-information deterministic game: battleship, bingo    </li>\n<li>inperfect-information incomplete-information stochastic game: most of the table/computer games</li>\n</ul>\n<h2 id=\"Chap02-Basic-Search-Algorithms\"><a href=\"#Chap02-Basic-Search-Algorithms\" class=\"headerlink\" title=\"Chap02 Basic Search Algorithms\"></a>Chap02 Basic Search Algorithms</h2><ul>\n<li>Brute force</li>\n<li>Systematic brute-force search  <ul>\n<li>Breadth-first search (BFS)  </li>\n<li>Depth-first search (DFS)  <ul>\n<li>Depth-first Iterative-deepening (DFID)  </li>\n</ul>\n</li>\n<li>Bi-directional search</li>\n</ul>\n</li>\n<li>Heuristic search: best-first search  <ul>\n<li>A*  <ul>\n<li>IDA*</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Symbol-Definition\"><a href=\"#Symbol-Definition\" class=\"headerlink\" title=\"Symbol Definition\"></a>Symbol Definition</h3><ul>\n<li>Node branching factor <code>b</code><ul>\n<li>degree</li>\n<li>number of neighbor vertexs of a node</li>\n</ul>\n</li>\n<li>Edge branching factor <code>e</code><ul>\n<li>number of connected edges of a node</li>\n</ul>\n</li>\n<li>Depth of a solution <code>d</code><ul>\n<li>最短深度, <code>D</code> 為最長深度</li>\n<li>Root深度為0</li>\n</ul>\n</li>\n<li>If <code>b</code> and <code>e</code> are average constant number, <code>e</code> &gt;= <code>b</code>(兩個點之間可能有多條線)</li>\n</ul>\n<h3 id=\"Brute-force-search\"><a href=\"#Brute-force-search\" class=\"headerlink\" title=\"Brute-force search\"></a>Brute-force search</h3><p>Used information  </p>\n<ul>\n<li>initial state</li>\n<li>method to find adjacent states</li>\n<li>goal-checking method(whether current state is goal)  </li>\n</ul>\n<p>Pure brute-force search program <img data-src=\"/img/TCG/54GbBxV.png\" alt=\"\">  </p>\n<ul>\n<li>隨機走旁邊的一個點</li>\n<li>不記憶走過的路<ul>\n<li>May take infinite time</li>\n</ul>\n</li>\n<li>Pure Random Algorithm 應用<ul>\n<li>驗證碼(e.g. 虛寶)</li>\n<li>純隨機數</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"BFS-Breadth-First-Search\"><a href=\"#BFS-Breadth-First-Search\" class=\"headerlink\" title=\"BFS(Breadth-First Search)\"></a>BFS(Breadth-First Search)</h3><p><img data-src=\"/img/TCG/mrf0Egx.png\" alt=\"\"><br>deeper(N): 回傳與N相鄰的點<br>record parent state and backtrace to Find the path </p>\n<ul>\n<li><p>Space complexity: $O(b^d)$ → Too big!</p>\n</li>\n<li><p>Time complexity: $O(b^{d-1} * e)$     </p>\n<ul>\n<li>→ costs O(e) to find deeper(N), at most check b^(d-1) times(deeper(leaf) do not return new node)</li>\n</ul>\n</li>\n<li><p>Open list: nodes that are in the queue(candidate nodes)</p>\n</li>\n<li><p>Closed list: nodes that have been explored(assure not answer, can skip)</p>\n<ul>\n<li>Need a good algorithm to check for states in deeper(N) are visited or not<ul>\n<li>Hash  </li>\n<li>Binary search</li>\n</ul>\n</li>\n<li>not need to have because it won’t guarantee to improve the performance</li>\n<li>if it is possible to have no solution, Need to store nodes that are already visited </li>\n</ul>\n</li>\n<li><p>node： open list → check is goal or not, explore(deeper) → closed list</p>\n</li>\n</ul>\n<p>Property    </p>\n<ul>\n<li>Always finds optimal solution</li>\n<li>Do not fall into loops if goal exists(always “deeper”) </li>\n</ul>\n<h4 id=\"Disk-based-algorithm\"><a href=\"#Disk-based-algorithm\" class=\"headerlink\" title=\"Disk based algorithm\"></a>Disk based algorithm</h4><p><img data-src=\"/img/TCG/i8bbMET.png\" alt=\"\"></p>\n<p>Solution for huge space complexity</p>\n<ul>\n<li>disk: store main data</li>\n<li>memory: store buffers</li>\n</ul>\n<ul>\n<li>Store open list(QUEUE) in disk<ul>\n<li><strong>Append</strong> buffered open list to disk when memory is full or QUEUE is empty</li>\n</ul>\n</li>\n<li>Store closed list in disk and maintain them as sorted<ul>\n<li><strong>Merge</strong> buffered closed list with disk closed list when memory is full   </li>\n<li>delay cheking: check node in the closed list or not before being taken from open list</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Disk-based-algorithms\"><a href=\"#Disk-based-algorithms\" class=\"headerlink\" title=\"Disk based algorithms\"></a>Disk based algorithms</h4><ul>\n<li>not too slow<ul>\n<li>read large file in sequence<ul>\n<li>queue(always retrieve at head and write at end)</li>\n</ul>\n</li>\n<li>sorting of data in disk<ul>\n<li>merge sort between disk list and buffer list</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>very slow<ul>\n<li>read file in random order(disk spinning)</li>\n</ul>\n</li>\n<li>系統為資源和效率(時間、空間、錢)的trade-off</li>\n</ul>\n<h3 id=\"DFS\"><a href=\"#DFS\" class=\"headerlink\" title=\"DFS\"></a>DFS</h3><p><img data-src=\"/img/TCG/65RmOgp.png\" alt=\"DFSalgo\">  </p>\n<ul>\n<li>performance mostly depends on <strong>move ordering</strong><ul>\n<li>If first choose the branch include the goal, find answer quick</li>\n<li>get out of long and wrong branches ASAP!</li>\n<li>implement <code>next(current, N)</code><ul>\n<li>作用：列舉出N的所有鄰居</li>\n<li>回傳下一個N的鄰居，目前列舉到current</li>\n<li>next(null, N) -&gt; return first neighbor of N</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>time complexity: $O(e^D)$<ul>\n<li>number of possible branches at depth D</li>\n</ul>\n</li>\n<li>space complexity: $O(D)$<ul>\n<li>Only need to store current path in the Stack</li>\n</ul>\n</li>\n</ul>\n<p>Property  </p>\n<ul>\n<li>need to store close list (BFS: do not need to)</li>\n<li>May not find an optimal solution</li>\n<li>Can’t properly implement on disk<ul>\n<li>very huge closed list<ul>\n<li>Use data compression or bit-operation techniques to store visited nodes</li>\n<li>Need a good heuristic to store the most frequently visited nodes to avoid swapping too often</li>\n</ul>\n</li>\n<li>need to check closed list instantly(BFS: can be delayed)</li>\n</ul>\n</li>\n<li>Can DFS be paralleled? Computer scientists fails to do so even after 30 years</li>\n<li>Most critical drawback: huge and unpredictable time complexity</li>\n</ul>\n<h3 id=\"General-skills-to-improve-searching-algorithm\"><a href=\"#General-skills-to-improve-searching-algorithm\" class=\"headerlink\" title=\"General skills to improve searching algorithm\"></a>General skills to improve searching algorithm</h3><h4 id=\"Iterative-Deepening-ID-逐層加深\"><a href=\"#Iterative-Deepening-ID-逐層加深\" class=\"headerlink\" title=\"Iterative-Deepening(ID) 逐層加深\"></a>Iterative-Deepening(ID) 逐層加深</h4><ul>\n<li>inspired from BFS(BFS = BFID)</li>\n<li>限制搜尋時的複雜度，若找不到再放寬限制</li>\n<li>prevent worse cases</li>\n</ul>\n<p>Deep First ID(DFID)     </p>\n<ul>\n<li>限制深度 <ul>\n<li>找到解立即return <img data-src=\"/img/TCG/9X2ZiRm.png\" alt=\"\"></li>\n<li><img data-src=\"/img/TCG/gmD51AT.png\" alt=\"\"></li>\n<li>time complexity using 二項式定理 <img data-src=\"/img/TCG/IfDEwFh.png\" alt=\"\"> <img data-src=\"/img/TCG/d0m27cU.png\" alt=\"\"><ul>\n<li>M(e, d) ~ $O(e^d)$ when e is sufficiently large</li>\n<li>→ no so much time penalty to use ID when e is big enough</li>\n</ul>\n</li>\n<li>關鍵：設定初始限制和限制放寬的大小</li>\n<li>always find optimal solution</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Bi-directional-search\"><a href=\"#Bi-directional-search\" class=\"headerlink\" title=\"Bi-directional search\"></a>Bi-directional search</h4><p><img data-src=\"/img/TCG/1-1.png\" alt=\"DFSdir\">  </p>\n<ul>\n<li><p><code>DFSdir(B, G, successor, i)</code>: DFS with starting states B, goal states G, successor function and <strong>depth limit i</strong>  </p>\n</li>\n<li><p><code>nextdir(current, successor, N)</code>: returns the state next to the state “current” in successor(N)</p>\n<ul>\n<li><code>deeper(current, N)</code> for forward searching<ul>\n<li>deeper(N) contains all next states of N</li>\n</ul>\n</li>\n<li><code>prev(current, N)</code> for backward searching<ul>\n<li>prev(N) contains all previous states of N<br><img data-src=\"/img/TCG/1-2.png\" alt=\"BDS\"></li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>Forward Search: store all states H</p>\n</li>\n<li><p>Backward Search: find the path from G(goal) to H at depth = limit or limit+1(for odd-lengthed solutions)  </p>\n</li>\n<li><p>also use the concept of iterative-deepening<br><img data-src=\"/img/TCG/7iBkfKB.png\" alt=\"\"></p>\n</li>\n<li><p>Time complexity: $O(e^{d/2})$</p>\n<ul>\n<li>the number of nodes visited is greatly reduced(compared with original $O(e^d)$)</li>\n</ul>\n</li>\n<li><p>Space complexity: $O(e^{d/2})$</p>\n<ul>\n<li>Pay the price of storing state depth(H)</li>\n</ul>\n</li>\n<li><p>restrict</p>\n<ul>\n<li>can’t assure to find optimal solution</li>\n<li>need to know what the goals are <ul>\n<li>bi-directional search is used when goal is known, only want to find path, like solving 15-puzzle</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Heuristic-啟發式-search\"><a href=\"#Heuristic-啟發式-search\" class=\"headerlink\" title=\"Heuristic(啟發式) search\"></a>Heuristic(啟發式) search</h3><p>Definition: criteria, methods, or principles for deciding which is the most effective to achieve some goal<br>→ By 經驗法則(so not always have optimal solution)  </p>\n<ul>\n<li>先走最有可能通往答案的state(good move ordering)<ul>\n<li>best-first algorithm : like greedy   </li>\n</ul>\n</li>\n<li>The unlikely path will be explored further(pruning)  </li>\n<li><strong>Key: how to pick the next state to explore</strong>   <ul>\n<li>need simple and effective <strong>estimate function</strong> to discriminate    </li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Heuristic-search-–-A\"><a href=\"#Heuristic-search-–-A\" class=\"headerlink\" title=\"Heuristic search – A*\"></a>Heuristic search – A*</h4><p><img data-src=\"/img/TCG/Vv8N3hj.png\" alt=\"A*\"><br>line 12: add all possible path that depth = depth + 1   </p>\n<ul>\n<li>Open list: a priorty queue(PQ) to store paths with costs</li>\n<li>Closed list: store all visited nodes with the smallest cost<ul>\n<li>Check for duplicated visits in the closed list only</li>\n<li>A node is inserted if <ul>\n<li>it has never been visited before</li>\n<li>being visited, but has smaller cost</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>Given a path P<ul>\n<li>g(P) = current cost of P</li>\n<li>h(P) = estimation of remaining path to goal(<strong>heuristic cost</strong> of P)</li>\n<li>f(P) = g(P) + h(P) is the cost function</li>\n</ul>\n</li>\n<li>Assume all costs are positive, so there is no need to check for falling into a loop  </li>\n<li>cost function所推測的cost不可超過實際的cost，否則不保證找到最佳解<ul>\n<li><strong>if h() never overestimates the actual cost to the goal</strong> (called admissible可容許), then <strong>A* always finds an optimal solution</strong></li>\n<li>證明？</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li>h(n)=0 : A* 等同 BFS</li>\n<li>h(n)&lt;目前節點到結束點的距離 : A* 演算法保證找到最短路徑, h(n)越小, 搜尋深度越深(代表花愈多時間)</li>\n<li>h(n)=目前節點到結束點的距離 : A* 演算法僅會尋找最佳路徑, 並且能快速找到結果(最理想情況)</li>\n<li>h(n)&gt;目前節點到結束點的距離 : 不保證能找到最短路徑, 但計算比較快</li>\n<li>h(n)與g(n)高度相關 : A* 演算法此時成為Best-First Search<br><span class=\"exturl\" data-url=\"aHR0cDovL2Jsb2cubWluc3RyZWwuaWR2LnR3LzIwMDQvMTIvc3Rhci1hbGdvcml0aG0uaHRtbA==\">http://blog.minstrel.idv.tw/2004/12/star-algorithm.html<i class=\"fa fa-external-link-alt\"></i></span></li>\n</ol>\n<p>Question:  </p>\n<ul>\n<li>What disk based techniques can be used?</li>\n<li>Why do we need a non-trivial h(P) that is admissible?</li>\n<li>How to design an admissible cost function?</li>\n</ul>\n<h3 id=\"DFS-with-threshold\"><a href=\"#DFS-with-threshold\" class=\"headerlink\" title=\"DFS with threshold\"></a>DFS with threshold</h3><ul>\n<li><code>DFScost(N, f, threshold)</code><ul>\n<li>starting state N </li>\n<li>cost function f</li>\n<li>cuts off a path if cost bigger than threshold </li>\n</ul>\n</li>\n</ul>\n<p><code>DFS1</code>: Use <code>next1(current,N)</code> find neighbors of N (in the order of low cost to high cost)<br><img data-src=\"/img/TCG/csd9mLf.png\" alt=\"dfs1\"><br><code>DFS2</code>: Use a priority queue instead of using a stack in <code>DFScost</code><br><img data-src=\"/img/TCG/jthjSm8.png\" alt=\"dfs2\"><br>It may be costly to maintain a priority queue</p>\n<h3 id=\"IDA-DFID-A\"><a href=\"#IDA-DFID-A\" class=\"headerlink\" title=\"IDA* = DFID + A*\"></a>IDA* = DFID + A*</h3><p>用A*的cost作為DFS的threshold<br><img data-src=\"/img/TCG/PJ2bPrX.png\" alt=\"\"> </p>\n<p>Ex. 15 puzzle<br>all posibilities: $16! \\leq 2.1 \\times 10^{13}$<br>g(P): the number of moves made so far<br>h(P): <strong>Manhattan distance</strong> between the current board and the goal<br>Manhattan distance from (i, j) to (i’, j’) is |i’ - i| + |j’ - j| (admissible)   </p>\n<h3 id=\"basic-thought-for-a-problem\"><a href=\"#basic-thought-for-a-problem\" class=\"headerlink\" title=\"basic thought for a problem\"></a>basic thought for a problem</h3><p><em>What you should think about before playing a game</em>：</p>\n<ul>\n<li>Needed to <ul>\n<li>Find an optimal solution?</li>\n<li>batch operations?</li>\n<li>disk based algorithms?</li>\n<li>Search in parallel?</li>\n</ul>\n</li>\n<li><strong>Balancing</strong> in resource usage:<ul>\n<li>memorize past results vs efforts to search again(time and space)</li>\n<li>The efforts to compute a better heuristic(time to think a heuristic?)</li>\n<li>The amount of resources spent in implementing a better heuristic and the amount of resources spent in searching(complexity of heuristic function)</li>\n</ul>\n</li>\n<li>For specific algorithm<ul>\n<li>heuristic : How to design a good and non-trivial heuristic function?</li>\n<li>DFS : How to get a better move ordering?</li>\n</ul>\n</li>\n</ul>\n<p>Can these techniques be applied to two-person game?</p>\n<h3 id=\"algorithm整理\"><a href=\"#algorithm整理\" class=\"headerlink\" title=\"algorithm整理\"></a>algorithm整理</h3><p>| Name      | Time Complexity | Space Complexity | OptimalSolution    | UseDisk | Description               |<br>| ——— | ————— | —————- | —————— | ——- |<br>| brute     | $∞$             | $O(1)$           | No                 | No      |<br>| BFS       | $O(b^d)$        | $O(b^{d-1} * e)$ | Yes                | Needed  |<br>| DFS       | $O(e^d)$        | $O(d)$           | No                 | NoNeed  |<br>| Heuristic | N\\A             | N\\A              | Yes, if admissible | –      | Ex. A*                    |<br>| BDS       | $O(e^{d/2})$    | $O(e^{d/2})$     | No                 | Needed  | DFS + bidiretional search |<br>| DFID      | $O(e^d)$        | $O(d)$           | Yes                | NoNeed  | DFS + ID                  |<br>| IDA*      | N\\A             | N\\A              | Yes                | N\\A     | DFID + A*                 |</p>\n<h2 id=\"Chap03-Heuristic-Search-with-Pre-Computed-Databases\"><a href=\"#Chap03-Heuristic-Search-with-Pre-Computed-Databases\" class=\"headerlink\" title=\"Chap03 Heuristic Search with Pre-Computed Databases\"></a>Chap03 Heuristic Search with Pre-Computed Databases</h2><p>new form of heuristic called <strong>pattern databases</strong></p>\n<ul>\n<li>If the subgoals can be divided<ul>\n<li>Can sget better admissible cost function by <strong>sum of costs of the subgoals</strong></li>\n</ul>\n</li>\n<li>Make use of the fact that computers can memorize lots of patterns<ul>\n<li>使用已經計算過的 pattern 來做出更好、更接近real cost的heuristic function </li>\n</ul>\n</li>\n</ul>\n<p>Using 15 puzzle as example <img data-src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/9/91/15-puzzle.svg/480px-15-puzzle.svg.png\" alt=\"\">  </p>\n<ul>\n<li>State space can be divided into two subsets: even and odd permutations</li>\n<li>$f_1$ is number of inversions in a permutation <code>X1X2...XN</code>  <ul>\n<li>inversion is a distinct pair Xi &gt; Xj such that i &lt; j(後面有幾個數比自己小) </li>\n<li>Example: <code>10,8,12,3,7,6,2,1,14,4,11,15,13,9,5</code> has 9+7+9+2+5+4+1+0+5+0+2+3+2+1 inversions</li>\n</ul>\n</li>\n<li>$f_2$ is the row number that empty cell is(空的那一格在哪一行)</li>\n<li>f = $f_1$ + $f_2$</li>\n<li>Slide a tile never change the parity    <ul>\n<li>Proof: skip(a lot of)</li>\n</ul>\n</li>\n</ul>\n<p>Solving Result</p>\n<ul>\n<li>1-MIPS machine</li>\n<li>30 CPU minutes in 1985 </li>\n<li>using IDA* with Manhattan distance heuristic</li>\n</ul>\n<h3 id=\"Non-additive-pattern-databases\"><a href=\"#Non-additive-pattern-databases\" class=\"headerlink\" title=\"Non-additive pattern databases\"></a>Non-additive pattern databases</h3><ul>\n<li>原本cost funtion為15片個別的distance之和，若能一次計算多片的distance？</li>\n<li>linear conflict: 靠很近不代表步數少(如[2, 1, 3, 4]交換至[1, 2, 3, 4]並不只兩步)<ul>\n<li>有可能移成pattern時，反而使其他片遠離</li>\n<li><img data-src=\"/img/TCG/4-1.png\" alt=\"linear conflict\"></li>\n</ul>\n</li>\n<li>Fringe(初級知識)<ul>\n<li>subset of selected tiles called <strong>pattern</strong><ul>\n<li>tiles not selected is “don’t-care tile”, all looked as the same</li>\n</ul>\n</li>\n<li>If there are 7 selected tiles, including empty cell  <ul>\n<li>16!/9! = 57657600 possible pattern size</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><img data-src=\"/img/TCG/4-2.png\" alt=\"prefrin\"><br>goal fringe: 選擇的方塊都和goal的位置一樣<br><img data-src=\"/img/TCG/4-3.png\" alt=\"goalfrin\"></p>\n<ul>\n<li>precompute the minimum number of moves(<strong>fringe number</strong>) to make goal fringe<ul>\n<li>goal fringe: 找給定的選擇方塊，在任何pattern中，最小需要移動成最終目標的步數</li>\n<li>We can solve it because the pattern size is relatively small</li>\n</ul>\n</li>\n<li>Pro’s<ul>\n<li>pattern size↑, fringe number↑, which means better estimation<ul>\n<li>because estimate number it is closer to the real answer    </li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Con’s    <ul>\n<li>Pattern with a larger size<ul>\n<li>consuming lots of memory and time</li>\n<li>limited by source</li>\n</ul>\n</li>\n<li>not optimal</li>\n</ul>\n</li>\n</ul>\n<p>Property   </p>\n<ol>\n<li>Divide and Conquer  </li>\n</ol>\n<ul>\n<li>Reduce a 15-puzzle problem into a 8-puzzle <img data-src=\"/img/TCG/4-4.png\" alt=\"15-8\"></li>\n<li>魔術方塊 – 分成六面</li>\n<li>Cannot easily combine<ul>\n<li>affect tiles that have reached the goal in the subproblem when solving the remains</li>\n</ul>\n</li>\n</ul>\n<ol start=\"2\">\n<li>Used as heuristic function(admissible)</li>\n</ol>\n<h3 id=\"More-than-one-patterns\"><a href=\"#More-than-one-patterns\" class=\"headerlink\" title=\"More than one patterns\"></a>More than one patterns</h3><ul>\n<li>How to Find better patterns for fringes?<ul>\n<li>→ Can we combine smaller patterns to form bigger patterns?</li>\n</ul>\n</li>\n</ul>\n<p>For different pattern databases P1, P2, P3 …  </p>\n<ul>\n<li>patterns may not be disjoint, may be overlapping</li>\n<li>The heuristic function we can use is<ul>\n<li>$h(P_1, P_2, P_3 … ) = max{h(P_1),h(P_2),h(P_3) …}$</li>\n</ul>\n</li>\n</ul>\n<p>How to make heuristics and the patterns disjoint?  </p>\n<ul>\n<li>patterns should be disjoint to add them together(see below)<ul>\n<li>Though patterns are disjoint, their costs are not disjoint<ul>\n<li>Some moves are counted more than once</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>f(P1) + f(P2) is admissible if  </p>\n<ol>\n<li>f() is disjoint with respect to P1 and P2</li>\n<li>both f(P1) and f(P2) are admissible</li>\n</ol>\n<p>For Manhattan distance heuristic  </p>\n<ol>\n<li>Each region is a tile<ul>\n<li><strong>Divide the board into several disjoint regions</strong></li>\n</ul>\n</li>\n<li>They are disjoint<ul>\n<li><strong>only count the number of moves made by each region</strong><ul>\n<li>doesn’t count cross-region moves</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<p>Refinement<br>Partition the board into disjoint regions using the tiles in a region of the goal arrangement as a pattern<br><img data-src=\"/img/TCG/4-5.png\" alt=\"aabb\"><br><strong>只算每個region內的片所移動的步數和，作為新定義的fringe number</strong><br>如此一來，就可以將每個region的cost相加而保持admissible</p>\n<h3 id=\"Disjoint-pattern\"><a href=\"#Disjoint-pattern\" class=\"headerlink\" title=\"Disjoint pattern\"></a>Disjoint pattern</h3><p>A heuristic function f() is disjoint with respect to two patterns P1 and P2 if  </p>\n<ol>\n<li>P1 and P2 have no common cells</li>\n<li>The solutions corresponding to f(P1) and f(P2) do not interfere each other</li>\n</ol>\n<p>Revised fringe number f’(p): for each fringe arrangement F, the <strong>minimum</strong> number of <strong>fringe-only</strong> moves to make goal fringe</p>\n<h3 id=\"Result\"><a href=\"#Result\" class=\"headerlink\" title=\"Result\"></a>Result</h3><p>Solves the 15 puzzle problem using fringe that is more than <strong>2000</strong> times faster than the previous result by using the Manhattan distance  </p>\n<ul>\n<li>The average Manhattan distance is 76.078 moves in 24-puzzle    </li>\n<li>The average value for the disjoint database heuristic is 81.607 moves in 24-puzzle   </li>\n<li><strong>only small refinement on heuristic function would make performance far better</strong>  </li>\n</ul>\n<p>Other heuristics   </p>\n<ul>\n<li>pairwise distance<ul>\n<li>partition the board into many 2-tiles so that the sum of cost is <strong>maximized</strong><br>For an $n^2 - 1$ puzzle, we have $O(n^4)$ different combinations<br>using</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"What-else-can-be-done\"><a href=\"#What-else-can-be-done\" class=\"headerlink\" title=\"What else can be done?\"></a>What else can be done?</h3><ol start=\"2\">\n<li>Better way of partitioning</li>\n<li>Is it possible to generalize this result to other problem domains?</li>\n<li>Decide ratio of the time used in searching and the time used in retrieving pre-computed knowledge<ul>\n<li>memorize vs compute</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"Chap-04-Two-Player-Perfect-Information-Games-Introductions\"><a href=\"#Chap-04-Two-Player-Perfect-Information-Games-Introductions\" class=\"headerlink\" title=\"Chap 04 Two-Player Perfect Information Games Introductions\"></a>Chap 04 Two-Player Perfect Information Games Introductions</h2><blockquote>\n<p>Conclusion: decision complexity is more important than state-space complexity   </p>\n</blockquote>\n<p>trade-off between <strong>knowledge-based</strong> methods and <strong>brute-force</strong> methods</p>\n<p>Domain: 2-person <strong>zero-sum games</strong> with perfect information<br>Zero-sum means one player’s loss is exactly the other player’s gain, and vice versa.</p>\n<h3 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><p>Game-theoretic value: the outcome of a game when all participants play optimally<br>Game-theoretic value for most games are unknown or are only known for some legal positions.</p>\n<table>\n<thead>\n<tr>\n<th>Type</th>\n<th>Description</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Ultra-weakly solved</td>\n<td>在初始盤面可知，遊戲中先行者或後行者誰有必勝、或必不敗之策略</td>\n</tr>\n<tr>\n<td>Weakly solved</td>\n<td>for the initial position a strategy has been determined to achieve the game-theoretic value(知道必不敗之策略為何)</td>\n</tr>\n<tr>\n<td>Strongly solved</td>\n<td>a strategy has been determined for all legal positions(任何合法情況都能知道最佳策略)</td>\n</tr>\n</tbody></table>\n<p>State-space complexity of a game: the <strong>number of the legal positions</strong> in a game(可能的盤面)<br>Game-tree complexity(decision complexity) of a game: the <strong>number of the leaf nodes</strong> in a solution search tree(可能的走法)  </p>\n<p>A fair game: the game-theoretic value is draw and both players have roughly equal probability on making a mistake.  </p>\n<ul>\n<li>Paper-scissor-stone</li>\n<li>Roll a dice and compare who gets a larger number</li>\n</ul>\n<p>Initiative(主動): the right to move first  </p>\n<ul>\n<li>A convergent game: the size of the state space decreases as the game progresses  <ul>\n<li>Example: Checkers  </li>\n</ul>\n</li>\n<li>A divergent game: the size of the state space increases as the game progresses  <ul>\n<li>Example: Connect-5 </li>\n</ul>\n</li>\n<li>A game may be convergent at one stage and then divergent at other stage.<ul>\n<li>Ex. Go, Tic-Tac-Toe</li>\n</ul>\n</li>\n</ul>\n<p>Threats are something like forced moved or moves you have little choices.<br>Threats are moves with predictable counter-moves</p>\n<h3 id=\"Classification\"><a href=\"#Classification\" class=\"headerlink\" title=\"Classification\"></a>Classification</h3><p><img data-src=\"/img/TCG/5-1.png\" alt=\"4\"></p>\n<p>Questions to be researched<br>Can perfect knowledge obtained from solved games be translated into rules and strategies which human beings can assimilate?<br>Are such rules generic, or do they constitute a multitude of ad hoc recipes?<br>Can methods be transferred between games?  </p>\n<p>Connection games<br>Connect-four (6 * 7)<br>Qubic (4 * 4 * 4)<br>Renju - Does not allow the First player to play certain moves, An asymmetric game.<br>mnk-Game: a game playing on a board of m rows and n columns with the goal of obtaining a straight line of length k.<br>Variations: First ply picks only one stone, the rest picks two stones in a ply. -&gt; Connect 6. </p>\n<p>Hex (10 * 10 or 11 * 11)<br>Exactly one of the players can win.<br>solved on a 6 * 6 board in 1994.</p>\n<p><img data-src=\"/img/TCG/5-2.png\" alt=\"Hex\"></p>\n<p>Proof on exactly one player win<br>Assume there is no winner<br><img data-src=\"/img/TCG/5-3.png\" alt=\"block\"><br>blue should totally block red at some place -&gt; blue will connect!  </p>\n<p>let R be the set of red cells that can be reached by chains from rightmost column<br>R does not contain a cell of the leftmost column; otherwise we have a contradiction<br>let N(R) be the blue cells that can be reached by chains originated from the rightmost column.<br>N(R) must contain a cell in the top and bottom row , Otherwise, R contains all cells in the First/bottom row, which is a contradiction.<br>N(R) must be connected. Otherwise, R can advance further. Hence N(R) is a blue winning chain.</p>\n<h3 id=\"Strategy-stealing-argument\"><a href=\"#Strategy-stealing-argument\" class=\"headerlink\" title=\"Strategy-stealing argument\"></a>Strategy-stealing argument</h3><p>made by John Nash in 1949<br>後手無一般化的必勝法<br>若後手有必勝法，則先手可以先隨機下一子(並無視之)，再照著後手的下法<br>後手必勝的下法包含了第一手，則再隨機下一子，將其視為第一子<br>限制：不能有和，下子不會有害，symmetric，history independent，</p>\n<p>Assume the initial board position is B0<br>f(B) has a value only when it is a legal position for the second player.<br>rev(x): interchange colors of pieces in a board or ply x.<br>always has exactly one winner  </p>\n<p>Not Solved<br>Chess DEEP BLUE beat the human World Champion in 1997<br>Chinese chess Professional 7-dan in 2007<br>Shogi<br>Claimed to be professional 2-dan in 2007<br>Defeat a 68-year old 1993 Meijin during 2011 and 2012</p>\n<p>Go<br>Recent success and breakthrough using Monte Carlo UCT based methods.<br>Amateur 1 dan in 2010.<br>Amateur 3 dan in 2011.<br>The program Zen beat a 9-dan professional master at March 17, 2012<br>  First game: Five stone handicap and won by 11 points<br>  Second game: four stones handicap and won by 20 points</p>\n<p><img data-src=\"/img/TCG/5-4.png\" alt=\"table of complexity\"></p>\n<p>possible to use heuristics to prune tremendously when the structure of the game is well studied</p>\n<p>Methods to solve games<br>Brute-force methods  </p>\n<ul>\n<li>Retrograde analysis(倒推)</li>\n<li>Enhanced transposition-table methods(?)<br>Knowledge-based methods  </li>\n<li>Threat-space search and lambda-search</li>\n<li>Proof-number search</li>\n<li>Depth-First proof-number search</li>\n<li>Pattern search<ul>\n<li>search threat patterns, which are collections of cells in a position</li>\n<li>A threat pattern can be thought of as representing the relevant area on the board<br>Recent advancements  </li>\n</ul>\n</li>\n<li>Monte Carlo UCT based game tree simulation<ul>\n<li>Monte Carlo method has a root from statistic</li>\n<li>Biased sampling</li>\n<li>Using methods from machine learning</li>\n<li>Combining domain knowledge with statistics</li>\n</ul>\n</li>\n<li>A majority vote algorithm</li>\n</ul>\n<p>low state-space complexity have mainly been solved with brute-force methods.<br>Nine Men’s Morris</p>\n<p>low game-tree-complexities have mainly been solved with knowledge-based methods.<br>by intelligent (heuristic) searching with help of databases<br>Go-Moku, Renju, and k-in-a-row games</p>\n<p>The First player has advantages.<br>Two kinds of positions<br>P-positions: the previous player can force a win.<br>N-positions: the next player can force a win.</p>\n<p>First player to have a forced win, just one of the moves that make P-position.<br>second player to have a forced win, all of the moves must lead to(造成) N-positions</p>\n<p>At small boards, the second player is able to draw or even to win for certain games.</p>\n<p>Try to obtain a small advantage by using the initiative.<br>The opponent must react adequately on the moves played by the other player.<br>Force the opponent to always play the moves you expected.</p>\n<p>Offsetting the initiative</p>\n<p>一子棋 by 張系國 棋王 -&gt; 先手優勢極大，隨著棋子增加，所需贏的步數就愈少。</p>\n<p>讓子<br>Ex. Go k = 7.5 in 2011</p>\n<p>Enforce rules so that the first player cannot win by selective patterns.<br>Ex. Renju</p>\n<p>The one-move-equalization rule: one player plays an opening move and the other player then has to decide which color to<br>play for the reminder of the game.<br>. Hex.<br>. Second-player will win.</p>\n<p>The First move plays one stone, the rest plays two stones each.<br>Can’t prove it is fair</p>\n<p>The first player uses less resource.<br>For example: using less time.<br>Ex. Chinese chess.</p>\n<p>1990’s prediction at 2000<br><img data-src=\"/img/TCG/5-5.png\" alt=\"\"><br>2000’s prediction at 2010<br><img data-src=\"/img/TCG/5-6.png\" alt=\"\"></p>\n<h2 id=\"Chap-05-Computer-chess-programming-by-Shannon\"><a href=\"#Chap-05-Computer-chess-programming-by-Shannon\" class=\"headerlink\" title=\"Chap 05 Computer chess programming by Shannon\"></a>Chap 05 Computer chess programming by Shannon</h2><p>C.E. Shannon</p>\n<ul>\n<li>1916 ~ 2001.</li>\n<li>The founding father of Information theory.</li>\n<li>The founding father of digital circuit design.</li>\n</ul>\n<p>Ground breaking paper for computer game playing: “Programming a Computer for Playing Chess”, 1950.<br>Presented many novel ideas that are still being used today.(太神啦！)  </p>\n<h3 id=\"Analysis\"><a href=\"#Analysis\" class=\"headerlink\" title=\"Analysis\"></a>Analysis</h3><ul>\n<li>typical 30 legal moves in one ply(下子)  </li>\n<li>typical game last about 40 moves  <ul>\n<li>will be 10^120 variations  </li>\n</ul>\n</li>\n<li>possible legal position(state space complexity) is roughly 10^43</li>\n<li>CPU speed in 1950 is 10^6 per second current CPU speed is 10^9 per second, still not fast enough to brute force it</li>\n</ul>\n<p>But it is possible to enumerate small endgames<br>3~6 piece endgame roughly 7.75*10^9 positions  </p>\n<h3 id=\"Three-phases-of-chess\"><a href=\"#Three-phases-of-chess\" class=\"headerlink\" title=\"Three phases of chess\"></a>Three phases of chess</h3><ul>\n<li>Opening <ul>\n<li>Development of pieces to good position</li>\n</ul>\n</li>\n<li>Middle<ul>\n<li>after opening until few pieces</li>\n<li>pawn structure </li>\n</ul>\n</li>\n<li>End game <ul>\n<li>concerning usage of pawns</li>\n</ul>\n</li>\n</ul>\n<p><strong>Different principles of play apply in the different phases</strong></p>\n<h3 id=\"Evaluating-Function\"><a href=\"#Evaluating-Function\" class=\"headerlink\" title=\"Evaluating Function\"></a>Evaluating Function</h3><p>position p, include board status, which side to move, history of moves<br>history -&gt; castling<br><img data-src=\"/img/TCG/6-1.png\" alt=\"\"></p>\n<p>Perfect evaluating function f(p):<br>f(p) = 1 for a won position.<br>f(p) = 0 for a drawn position.<br>f(p) = -1 for a lost position.<br>Perfect evaluating function is impossible for most games, and is <strong>not fun or educational</strong>.</p>\n<p>Factors considered in approximate evaluating functions:</p>\n<ul>\n<li>The relative values of differences in materials.<ul>\n<li>The values of queen, rook, bishop, knight and pawn are about 9, 5, 3, 3, and 1, respectively.</li>\n<li>How to determine good relative values? Static values verse dynamic values?</li>\n</ul>\n</li>\n<li>Position of pieces<ul>\n<li>Mobility: the freedom to move your pieces.</li>\n<li>at center , or at corner</li>\n<li>Doubled rooks</li>\n</ul>\n</li>\n<li>Pawn structure: the relative positions of the pawns.<ul>\n<li>Backward pawn: a pawn that is behind the pawn of the same color on an adjacent file that cannot advance without losing of itself.</li>\n<li>Isolated pawn: A pawn that has no friend pawn on the adjacent file.</li>\n<li>Doubled pawn: two pawns of the same color on the same file</li>\n<li>these three are all bad pawn</li>\n<li>Passed pawns: pawns that have no opposing pawns to prevent</li>\n<li>Pawns on opposite colour squares from bishop.</li>\n</ul>\n</li>\n<li>King safety.</li>\n<li>Threat and attack.<ul>\n<li>Attacks on pieces which give one player an option of exchanging</li>\n<li>Pins(小盯大) which mean here immobilizing pins where the pinned piece is of value not greater than the pinning piece</li>\n<li>Commitments -&gt; 需要保護其他子</li>\n</ul>\n</li>\n<li><img data-src=\"/img/TCG/6-2.png\" alt=\"three pawn\"></li>\n</ul>\n<p>Putting “right” coeffcients for diffferent factors<br>Dynamic setting in practical situations.</p>\n<p>evaluating function can be only applied in<br>relatively quiescent positions.</p>\n<p>not in the middle of material exchanging.<br>not being checked</p>\n<p>max-min strategy<br>In your move, you try to maximize your f(p).<br>In the opponent’s move, he tries to minimize f(p).</p>\n<p>A strategy in which all variations are considered out to a<br>definite number of moves and the move then determined from<br>a max-min formula is called type A strategy.</p>\n<p>Stalemate<br>Winning by making the opponent having no legal next move.<br>suicide move is not legal, and stalemate results in<br>a draw if it is not currently in check.</p>\n<p>Zugzwang(強制被動): In certain positions, a player is at a disadvantage if he is the next player to move.<br><img data-src=\"/img/TCG/6-3.png\" alt=\"\"></p>\n<p>Programming<br>    - Special rules of games<br>    - Methods of winning<br>    - Basic data structure for positions.<br>    - check for possible legal moves<br>    - Evaluating function.</p>\n<p>Forced variations(迫著)<br>one player has little or no choices in playing</p>\n<p>type B strategy<br>the machine must </p>\n<ol>\n<li><p>examine forceful variations out as far as possible and evaluate only at reasonable positions</p>\n</li>\n<li><p>select the variations to be explored by some process</p>\n<pre><code>| 1 if any piece is attacked by a piece of lower value,</code></pre><p>  g(P) =    /    or by more pieces then defences of if any check exists</p>\n<pre><code>\\    on a square controlled by opponent.\n | 0 otherwise.</code></pre><p>Using this function, variations could be explored until g(P)=0,</p>\n</li>\n</ol>\n<p><strong>effective branching factor</strong> is about 2 to 3.<br>Chinese chess has a larger real branching factor, but its average effective branching factor is also about 2 to 3.</p>\n<p>“style” of play by the machine can<br>be changed very easily by altering some of the coeffcients and<br>numerical factors involved in the evaluating function</p>\n<p>A chess master, on the other hand, has available knowledge of hundreds or perhaps thousands of standard situations, stock<br>combinations, and common manoeuvres based on pins, forks, discoveries, promotions, etc.<br>In a given position he recognizes some similarity to a familiar situation and this directs his mental calculations along the lines with greater probability of success.</p>\n<p>Need to re-think the goal of writing a computer program that<br>plays games.<br>To discover intelligence:<br>What is considered intelligence for computers may not be considered so for human.<br>To have fun:<br>A very strong program may not be a program that gives you the most pleasure.<br>To Find ways to make computers more helpful to human.<br>Techniques or (machine) intelligence discovered may be useful to computers performing other tasks</p>\n<h2 id=\"Chap-06-Alpha-Beta-Pruning\"><a href=\"#Chap-06-Alpha-Beta-Pruning\" class=\"headerlink\" title=\"Chap 06 Alpha-Beta Pruning\"></a>Chap 06 Alpha-Beta Pruning</h2><ul>\n<li>standard searching procedure for 2-person perfect-information zero sum games</li>\n<li>terminal position<ul>\n<li>a position whose (win/loss/draw) value can be know</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Dewey-decimal-system\"><a href=\"#Dewey-decimal-system\" class=\"headerlink\" title=\"Dewey decimal system\"></a>Dewey decimal system</h3><p>杜威分類法 <img data-src=\"/img/TCG/7-1.png\" alt=\"\"></p>\n<h3 id=\"Min-Max-method\"><a href=\"#Min-Max-method\" class=\"headerlink\" title=\"Min-Max method\"></a>Min-Max method</h3><p>假設持白子，數字為白子的evaluating function, 在下白子時，取分數最高(max)的，在下黑子時，取分數最低(min)的 <img data-src=\"/img/TCG/7-2.png\" alt=\"\"><br><img data-src=\"/img/TCG/7-3.png\" alt=\"max layer function F\"></p>\n<h3 id=\"Nega-max-method\"><a href=\"#Nega-max-method\" class=\"headerlink\" title=\"Nega-max method\"></a>Nega-max method</h3><p>將下黑子的分數取負號(即為黑子的分數，因為是零和遊戲)<br>這樣每一層都取最大分數即可<br><img data-src=\"/img/TCG/7-4.png\" alt=\"negamax algorithm\"></p>\n<p>優點是實作較快，程式碼簡潔 </p>\n<h3 id=\"Alpha-Beta-cut-off\"><a href=\"#Alpha-Beta-cut-off\" class=\"headerlink\" title=\"Alpha-Beta cut off\"></a>Alpha-Beta cut off</h3><ul>\n<li>current search window(score bound) = [α, β]</li>\n<li>If α &gt; β, no need to do further search in current branch </li>\n<li>initial alpha = -∞, beta = ∞</li>\n</ul>\n<p><img data-src=\"/img/TCG/7-5.png\" alt=\"Alpha Cut off\">  </p>\n<ul>\n<li>只要發現對手有一種反擊方式，使結果比其他手的結果還差，就砍掉這一手(branch)</li>\n<li>2.1 can cut off 2.x<ul>\n<li>before 2.1 , window = [15, ∞]</li>\n<li>after 2.1 , window = [15, 10]</li>\n</ul>\n</li>\n<li>We want to choose the biggest value at root for lower bound, so 2.x is all cut off</li>\n</ul>\n<p><img data-src=\"/img/TCG/7-6.png\" alt=\"Beta Cut off\">  </p>\n<ul>\n<li>只要對手發現自己有一種反擊方式，使結果比其他手的結果還差(α)，就砍掉這一手(branch)</li>\n<li>1.2.1 can cut off 1.2.x<ul>\n<li>beofre 1.2.1 , 1 bound is [-∞, 10]</li>\n<li>now 1.2 bound is [15, 10]</li>\n</ul>\n</li>\n<li>We want to choose smallest value at 1 for upper bound, 1.2.x is all cut off</li>\n</ul>\n<p>可以砍所有子孫 <img data-src=\"/img/TCG/7-7.png\" alt=\"Deep Cut off\">  </p>\n<ul>\n<li>2.1.1 is cut off   <ul>\n<li>root bound = [15, ∞]</li>\n<li>2.1.1 = [-∞, 7]</li>\n</ul>\n</li>\n</ul>\n<p><img data-src=\"/img/TCG/7-8.png\" alt=\"alpha-beta cut off Algorithm\"><br>f = white move, find max to be lower bound, do beta cut off<br>g = black move, find min to be upper bound, do alpha cut off<br><img data-src=\"/img/TCG/7-9.png\" alt=\"example\"></p>\n<p><img data-src=\"/img/TCG/7-10.png\" alt=\"F2\"><br>window變號，回傳的score也要變號<br>t = -F(pi, -beta, -m)</p>\n<h3 id=\"Analysis-for-AB-pruning\"><a href=\"#Analysis-for-AB-pruning\" class=\"headerlink\" title=\"Analysis for AB pruning\"></a>Analysis for AB pruning</h3><p><strong>different move orderings</strong> give very different cut branches<br>愈快找到最佳解，可以砍的branch愈多</p>\n<p>critical nodes 一定會搜到(cut off之前至少需搜完一個子branch) <img data-src=\"/img/TCG/7-11.png\" alt=\"Critical Node\"></p>\n<p>perfect-ordering tree: 每個branch的第一個child就是最佳解<br>Theorem: 若是perfect-ordering tree, AB pruning 會剛好走過所有 critical nodes<br>Proof:<br>Three Types of critial nodes  </p>\n<ul>\n<li>定義a_i = 第i層的node是第幾個child(杜威分類)</li>\n<li>a_j = 第一個「不是第一個child」的node(如果有的話)<ul>\n<li>a_j-1 = a_j+1 = 1<ul>\n<li>小於j的node都是1</li>\n<li>而且因為是critial node，所以a_j的child一定是1(其他會被砍掉)</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>a_l = the last layer</li>\n</ul>\n<ol>\n<li>root and all node = 1(最左邊, 1, 1.1, 1.1.1 …)</li>\n<li>l-j = even<ol>\n<li>j = l (type1 的全部兒子(除了最左邊))  </li>\n<li>j &lt; l (type3 的全部兒子)</li>\n</ol>\n</li>\n<li>l-j = odd<ol>\n<li>j+1 = l (type2.1 的第一個兒子)</li>\n<li>j+1 &lt; l (type2.2的第一個兒子)</li>\n</ol>\n</li>\n</ol>\n<p><img data-src=\"/img/TCG/7-13.png\" alt=\"Three Types of critial nodes\"><br><img data-src=\"/img/TCG/7-14.png\" alt=\"Proof\"></p>\n<p>We can calculate the least number of nodes to be searched <img data-src=\"/img/TCG/7-15.png\" alt=\"\"> <img data-src=\"/img/TCG/7-16.png\" alt=\"\"></p>\n<p>when there’re some early terminate nodes <img data-src=\"/img/TCG/7-18.png\" alt=\"\"><br>l = even → x.1.x.1… = b0(q1b2)q3…<br>            1.x.1.x… = (q0b1)(q2b3)…(q0b1 = 第一個孩子的全child，若無child，則為(1-qi)*0)</p>\n<p>Perfect ordering is not always best when tree are not balanced <img data-src=\"/img/TCG/7-17.png\" alt=\"\"><br>→ When <strong>“relative” ordering of children</strong>(not perfect order!) are good enough, there are some cut-off  </p>\n<p>Theorem: 若知道所有的分數，就可以最佳化alpha-beta pruning(計算的點最少，cut最多)<br>→ 不過如果能算出來就不用search了…</p>\n<h3 id=\"Variations-of-alpha-beta-search\"><a href=\"#Variations-of-alpha-beta-search\" class=\"headerlink\" title=\"Variations of alpha-beta search\"></a>Variations of alpha-beta search</h3><ul>\n<li>Fail hard alpha-beta cut(Original) : F2 <img data-src=\"/img/TCG/7-19.png\" alt=\"\"> <ul>\n<li>returned value in [α, β] <img data-src=\"/img/TCG/7-20.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>Fail soft alpha-beta cut(Variation): F3  <img data-src=\"/img/TCG/7-21.png\" alt=\"\"><ul>\n<li>Find “better” value when the value is out of the search window</li>\n<li>m is the value in this branch(not related to α)<ul>\n<li>use max(m, alpha) to get window </li>\n</ul>\n</li>\n<li>return original value m instead of α or β when cut off, which is more precise than fail-hard <img data-src=\"/img/TCG/7-22.png\" alt=\"\"></li>\n<li>Failed-high <ul>\n<li>return value &gt; β</li>\n</ul>\n</li>\n<li>Failed-low<ul>\n<li>return value &lt; α</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Comparison  </p>\n<ul>\n<li>fail-hard<ul>\n<li>return max{4000,200,v} <img data-src=\"/img/TCG/7-23.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>fail-soft<ul>\n<li>return max{200,v} <img data-src=\"/img/TCG/7-24.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>fail-soft provides more information when the true value is out of search window<ul>\n<li>can record better value to be used later when this position is revisited</li>\n<li>F3 saves about 7% of time than that of F2 when a transposition table is used to save and re-use searched results</li>\n<li>記錄F3傳回的值，可減少重複計算的時間，因為下一手的樹在下兩層，大部分node皆相同<ul>\n<li>if p1 is searched, p2 does not need to search again <img data-src=\"/img/TCG/7-25.png\" alt=\"\"></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Questions\"><a href=\"#Questions\" class=\"headerlink\" title=\"Questions\"></a>Questions</h3><ul>\n<li>What move ordering is good?<ul>\n<li>search the best possible move first</li>\n<li>cut off a branch with more nodes first</li>\n</ul>\n</li>\n<li>What is the effect of using iterative-deepening alpha-beta cut off?</li>\n<li>How about searching game graph instead of game tree?</li>\n<li>Can some nodes be visited more than once?</li>\n</ul>\n<h3 id=\"Pruning-Techinique\"><a href=\"#Pruning-Techinique\" class=\"headerlink\" title=\"Pruning Techinique\"></a>Pruning Techinique</h3><ul>\n<li>Exact algorithms: by mathematical proof<ul>\n<li>Alpha-Beta pruning</li>\n<li>Scout(in Chap07)</li>\n</ul>\n</li>\n<li>Approximated heuristics: pruned branches with low probability to be solution<ul>\n<li>in very bad position(盤面太差)</li>\n<li>a little hope to gain back the advantage(無法逆轉)</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Chap07-Scout-and-Proof-Number-Search\"><a href=\"#Chap07-Scout-and-Proof-Number-Search\" class=\"headerlink\" title=\"Chap07 Scout and Proof Number Search\"></a>Chap07 Scout and Proof Number Search</h2><ul>\n<li>Suppose we get at least score s at the First branch<ul>\n<li>want to find whether second branch can get score over s or not</li>\n</ul>\n</li>\n</ul>\n<p><strong>Is there a way to search a tree approximately?</strong>  </p>\n<h3 id=\"SCOUT\"><a href=\"#SCOUT\" class=\"headerlink\" title=\"SCOUT\"></a>SCOUT</h3><ul>\n<li>Invented by Judea Pearl in 1980</li>\n<li>first time: search approximately<ul>\n<li>if there is better value, search again</li>\n<li>first search can provide useful information in the second search </li>\n</ul>\n</li>\n<li>TEST whether Tb can return score &gt; v <img data-src=\"/img/TCG/test-algo.png\" alt=\"\"><ul>\n<li>if p is max node → success with only one subbranch &gt; v</li>\n<li>if p is min node → success with all subbranches &gt; v</li>\n<li>If success, then search Tb. else, <strong>no need to search Tb</strong></li>\n</ul>\n</li>\n<li>algorithm <img data-src=\"/img/TCG/scout-algo.png\" alt=\"\"><ul>\n<li>scout first branch and test other branch<ul>\n<li>if test success, update the value by scout this branch</li>\n</ul>\n</li>\n<li>recursive procedure<ul>\n<li>Every ancestor of you may initiate a TEST to visit you<ul>\n<li>will be visited at most d times(= depth)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Time Complexity  </p>\n<ul>\n<li><strong>not guarantee</strong>(but most of the time) that the visited nodes number are less than alpha-beta<ul>\n<li>may search a branch two times</li>\n<li>may pay many visits to a node that is cut off by alpha-beta</li>\n</ul>\n</li>\n<li>TEST: Ω(b^(d/2))<ul>\n<li>but has small argument and will be very small at the best situation <img data-src=\"/img/TCG/nodes-visited.png\" alt=\"node visited\"><ul>\n<li>if the first subbranch has the best value, then TEST scans the tree fast</li>\n<li>move ordering is very important</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Comparison<ul>\n<li>alpha-beta<ul>\n<li>cut off comes from bounds of search windows(by ancestors)</li>\n</ul>\n</li>\n<li>scout<ul>\n<li>cut off from previous branches’ score(by brothers)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Performance  </p>\n<ul>\n<li>SCOUT favors “skinny” game trees<ul>\n<li>Show great improvements on depth &gt; 3 for games with <strong>small branching factors</strong></li>\n<li>On depth = 5, it saves over 40% of time</li>\n</ul>\n</li>\n<li>AB + scout gets average 10~20% improvement than only AB</li>\n</ul>\n<p>Null(Zero) window search    </p>\n<ul>\n<li>Using alpha-beta search with the window [m,m + 1]<ul>\n<li>result will be failed-high or failed-low</li>\n</ul>\n</li>\n<li>Failed-high means return value &gt; m + 1<ul>\n<li>Equivalent to TEST(p; m;&gt;) is true</li>\n</ul>\n</li>\n<li>Failed-low means return value &lt; m<ul>\n<li>Equivalent to TEST(p; m;&gt;) is false</li>\n</ul>\n</li>\n<li>Using searching window is better than using a single bound in SCOUT</li>\n</ul>\n<p><img data-src=\"/img/TCG/nega-scout.png\" alt=\"\">    </p>\n<ul>\n<li>depth &lt; 3 → no alpha-beta pruning → return value is exact value(no need to search again)</li>\n<li>first-time search → do null window search(scout)</li>\n<li>research → do normal window a-b pruning</li>\n</ul>\n<p>Refinements  </p>\n<ul>\n<li>Use information from previous search<ul>\n<li>When a subtree is re-searched, restart from the position that the value is returned in first search</li>\n</ul>\n</li>\n<li>Change move ordering<ul>\n<li>Reorder the moves by priority list</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Proof-Number-Search\"><a href=\"#Proof-Number-Search\" class=\"headerlink\" title=\"Proof Number Search\"></a>Proof Number Search</h3><p><img data-src=\"https://chessprogramming.wikispaces.com/Proof-number+search#Pseudo%20Code\" alt=\"參考資料: chessprogramming: proof-number search\"></p>\n<p>binary valued game tree    </p>\n<ul>\n<li><p>2-player game tree with either 0 or 1 on the leaves</p>\n<ul>\n<li>and-or tree: min → and, max → or</li>\n</ul>\n</li>\n<li><p>most proving node for node u</p>\n<ul>\n<li>node that if its value is 1, then the value of u is 1</li>\n</ul>\n</li>\n<li><p>most disproving node for node u</p>\n<ul>\n<li>node that if its value is 0, then the value of u is 0</li>\n</ul>\n</li>\n<li><p>proof(u): minimum number of nodes to visit to make u = 1</p>\n</li>\n<li><p>disproof(u): minimum number of nodes to visit to make u = 0</p>\n</li>\n</ul>\n<p>If value(u) is unknown, then proof(u) is the cost of evaluating u  </p>\n<ul>\n<li>If value(u) is 1, then proof(u) = 0</li>\n<li>If value(u) is 0, then proof(u) = ∞</li>\n<li>proof number can be calculate by search childrens <img data-src=\"/img/TCG/proof-number.png\" alt=\"\"><ul>\n<li>disproof number → reverse calculate method of proof number</li>\n</ul>\n</li>\n</ul>\n<p>Usage  </p>\n<ul>\n<li>find child u that have min{proof(root); disproof(root)}</li>\n<li>if we try to <strong>prove</strong> it<ul>\n<li>pick a child with the <strong>least proof number</strong> for a <strong>MAX node</strong></li>\n<li>pick <strong>any node that has a chance to be proved</strong> for a <strong>MIN node</strong></li>\n</ul>\n</li>\n<li>if we try to <strong>disprove</strong> it<ul>\n<li>pick a child with the <strong>least disproof number</strong> for a <strong>MIN node</strong></li>\n<li>pick <strong>any node that has a chance to be disproved</strong> for a <strong>MAX node</strong></li>\n</ul>\n</li>\n<li>used in open game tree or an endgame tree because some proof or disproof number is known<ul>\n<li>1 → proved to win, 0 → proved to lose </li>\n<li>or used to achieve sub-goal in games</li>\n</ul>\n</li>\n</ul>\n<!-- why smallest number because proof need all 1? -->\n<p>Proof-Number search algorithm <img data-src=\"/img/TCG/pn-algo.png\" alt=\"\">  </p>\n<ol>\n<li>keep update number by bottom-up<ol>\n<li>compare proof number and disproof number of root</li>\n</ol>\n</li>\n<li>find the leaf to prove or disprove</li>\n</ol>\n<p>Multi-value game tree  </p>\n<ul>\n<li>value in [0, 1]</li>\n<li>$proof_v(u)$: the minimum number of leaves needed to visited to make u &gt;= v<ul>\n<li>proof(u) = $proof_1(u)$</li>\n</ul>\n</li>\n<li>$disproof_v(u)$: the minimum number of leaves needed to visited to make u &lt; v<ul>\n<li>disproof(u) = $disproof_1(u)$</li>\n</ul>\n</li>\n<li>use binary search to set upper bound of the value <img data-src=\"/img/TCG/multivalue-pn-algo.png\" alt=\"\"></li>\n</ul>\n<h2 id=\"Chap08-Monte-Carlo-Game-Tree-Search\"><a href=\"#Chap08-Monte-Carlo-Game-Tree-Search\" class=\"headerlink\" title=\"Chap08 Monte-Carlo Game Tree Search\"></a>Chap08 Monte-Carlo Game Tree Search</h2><h3 id=\"original-ideas\"><a href=\"#original-ideas\" class=\"headerlink\" title=\"original ideas\"></a>original ideas</h3><p>Algorithm $MCS_{pure}$ <img data-src=\"img/TCG/random-games.png\" alt=\"\">    </p>\n<ul>\n<li><p>For each possible next move</p>\n<ul>\n<li>play this move and then play a lot of random games(play every moves as random)</li>\n<li>calculate average score</li>\n</ul>\n</li>\n<li><p>Choose move with best score</p>\n</li>\n<li><p>Original version: GOBBLE in 1993  </p>\n<ul>\n<li>Performance is not good compared to other Go programs(alpha-beta)</li>\n</ul>\n</li>\n<li><p>Enhanced versions</p>\n<ul>\n<li>Adding the idea of minimax tree search</li>\n<li>Adding more domain knowledge</li>\n<li>Adding more searching techniques</li>\n<li>Building theoretical foundations from statistics, and on-line and off-line learning</li>\n<li>results<ul>\n<li>MoGo<ul>\n<li>Beat a professional human 8 dan(段) with a 8-stone handicap at January 2008</li>\n<li>Judged to be in a “professional level” for 9 x 9 Go in 2009</li>\n</ul>\n</li>\n<li>Zen<ul>\n<li>close to amateur 3-dan in 2011</li>\n<li>Beat a 9-dan professional master with handicaps at March 17, 2012<ul>\n<li>First game: Five stone handicap and won by 11 points</li>\n<li>Second game: four stones handicap and won by 20 points</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Disadvantage  </p>\n<ul>\n<li>average score search != minimax tree search<ul>\n<li>$MCS_{pure}$ prefer right branch, but it’s min value is low <img data-src=\"/img/TCG/minmax-and-avergae.png\" alt=\"\"></li>\n</ul>\n</li>\n</ul>\n<h3 id=\"First-Refinement-Monte-Carlo-based-tree-search\"><a href=\"#First-Refinement-Monte-Carlo-based-tree-search\" class=\"headerlink\" title=\"First Refinement: Monte-Carlo based tree search\"></a>First Refinement: Monte-Carlo based tree search</h3><p>Intuition   </p>\n<ul>\n<li>Best First tree growing<ul>\n<li>Expand one level of best leaf(which has largest score) <img data-src=\"/img/TCG/mct-ex2.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>if number of simulations is not enough, it can’t be a good simulation<ul>\n<li>on a MIN node, if not enough children are probed for enough number of times, you may miss a very bad branch</li>\n<li>take <strong>simulation count</strong> into consideration</li>\n</ul>\n</li>\n</ul>\n<p><img data-src=\"/img/TCG/MCT.png\" alt=\"\"><br><img data-src=\"/img/TCG/mct-ex1.png\" alt=\"\">  </p>\n<h3 id=\"Second-Refinement-UCT\"><a href=\"#Second-Refinement-UCT\" class=\"headerlink\" title=\"Second Refinement: UCT\"></a>Second Refinement: UCT</h3><ul>\n<li><p>Effcient sampling  </p>\n<ul>\n<li>Original: equally distributed among all legal moves</li>\n<li>Biased sampling: sample some moves more often than others</li>\n</ul>\n</li>\n<li><p>Observations</p>\n<ul>\n<li>Some moves are bad and do not need further exploring<ul>\n<li>Need to consider extremely bad luck sitiation<ul>\n<li>e.g. often “randomly” choose bad move and get bad score</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p><span class=\"exturl\" data-url=\"aHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvTXVsdGktYXJtZWRfYmFuZGl0\">K-arm bandit problem<i class=\"fa fa-external-link-alt\"></i></span>  </p>\n<ul>\n<li>Assume you have K slot machines each with a different payoff, i.e., expected value of returns ui, and an unknown distribution</li>\n<li>Assume you can bet on the machines N times, what is the best strategy to get the largest returns?</li>\n</ul>\n</li>\n<li><p>Ideas</p>\n<ul>\n<li>Try each machine a few, but enough, times and record their returns<ul>\n<li>For the machines that currently have the best returns, play more often later</li>\n<li>For the machines that currently return poorly, give them a chance sometimes to check their distributions are really bad or not</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>UCB: Upper Confidence Bound <img data-src=\"img/TCG/UCB.png\" alt=\"\">  </p>\n<ul>\n<li>Meaning<ul>\n<li>For a MAX node, Wi is the number of win’s for the MAX player</li>\n<li><strong>For a MIN node, Wi is the number of win’s for the MIN player</strong></li>\n<li>When N is approaching logN, then UCB is nothing but the current winning rate plus a constant</li>\n<li>When N getting larger, UCB will approachthe real winning rate</li>\n</ul>\n</li>\n<li>Expand for the move with the highest UCB value</li>\n<li><strong>only compare UCB scores among children of a node</strong><ul>\n<li>It is meaningless to compare scores of nodes that are not siblings</li>\n</ul>\n</li>\n<li>Using argument c to keep a balance between<ul>\n<li>Exploitation: exploring the best move so far</li>\n<li>Exploration: exploring other moves to see if they can be proved to be better <img data-src=\"/img/TCG/ucb-ex1.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>alternative<ul>\n<li>consider the variance of scores in each branch <img data-src=\"/img/TCG/UCB2.png\" alt=\"\"></li>\n</ul>\n</li>\n</ul>\n<p>UCT: Upper Confidence Bound for Tree  </p>\n<ul>\n<li>Maintain the UCB value for each node in the game tree<ul>\n<li>Pick path such that each node in this path has a largest UCB score among all of its siblings</li>\n<li>Pick the leaf node in the path which has been visited more than a certain amount of times to expand</li>\n</ul>\n</li>\n</ul>\n<p>Usable when the “density of goals” is suffciently large  </p>\n<ul>\n<li>When there is only a unique goal, Monte-Carlo based simulation may not be useful</li>\n</ul>\n<p>new MCT algorithm(with UCT) <img data-src=\"/img/TCG/mct-uct.png\" alt=\"\"></p>\n<h4 id=\"Implementation-hints\"><a href=\"#Implementation-hints\" class=\"headerlink\" title=\"Implementation hints\"></a>Implementation hints</h4><p><img data-src=\"/img/TCG/uct-imp.png\" alt=\"\"><br><img data-src=\"/img/TCG/uct-imp2.png\" alt=\"\"><br><img data-src=\"/img/TCG/uct-imp3.png\" alt=\"\"></p>\n<h3 id=\"When-to-use-Monte-Carlo\"><a href=\"#When-to-use-Monte-Carlo\" class=\"headerlink\" title=\"When to use Monte-Carlo\"></a>When to use Monte-Carlo</h3><ul>\n<li>huge branching number </li>\n<li>cannot easily compute good evaluating function</li>\n<li>Mostly used in Go, Bridge(?)</li>\n</ul>\n<p>Rule of Go(圍棋)  </p>\n<ul>\n<li>Ko(打劫): 不能有重複盤面</li>\n<li>可以跳過，不能下自殺步</li>\n<li>Komi: 先手讓子</li>\n</ul>\n<p>Implementation  </p>\n<ul>\n<li>partition stones into strings(使用共同氣的子) by DFS</li>\n<li>check empty intersection is an eye or not(check neighbors and limits)</li>\n</ul>\n<h3 id=\"Domain-independent-refinements\"><a href=\"#Domain-independent-refinements\" class=\"headerlink\" title=\"Domain independent refinements\"></a>Domain independent refinements</h3><p>Main considerations   </p>\n<ul>\n<li>Avoid doing un-needed computations</li>\n<li>Increase the speed of convergence</li>\n<li>Avoid early mis-judgement</li>\n<li>Avoid extreme bad cases</li>\n</ul>\n<p>Refinements  </p>\n<ul>\n<li>Progressive pruning  <ul>\n<li>Cut hopeless nodes early</li>\n</ul>\n</li>\n<li>All moves at first(AMAF)<ul>\n<li>Increase the speed of convergence</li>\n</ul>\n</li>\n<li>Node expansion<ul>\n<li>Grow only nodes with a potential</li>\n</ul>\n</li>\n<li>Temperature<ul>\n<li>Introduce randomness</li>\n</ul>\n</li>\n<li>Depth-i enhancement<ul>\n<li>With regard to Line 1, the initial phase, exhaustively enumerate all possibilities</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Progressive-pruning\"><a href=\"#Progressive-pruning\" class=\"headerlink\" title=\"Progressive pruning\"></a>Progressive pruning</h4><p>Each move has a mean value m and a standard deviation σ  </p>\n<ul>\n<li><p>Left expected outcome ml = m - rd * σ</p>\n</li>\n<li><p>Right expected outcome mr = m + rd * σ</p>\n<ul>\n<li>rd is argument</li>\n</ul>\n</li>\n<li><p>A move M1 is <strong>statistically inferior</strong> to another move M2 if M1.mr &lt; M2.ml</p>\n</li>\n<li><p>Two moves M1 and M2 are <strong>statistically equal</strong> if M1.σ &lt; σe and M2.σ &lt; σe and no move is statistically inferior to the other</p>\n<ul>\n<li>σe is argument which called standard deviation for equality</li>\n</ul>\n</li>\n</ul>\n<p>Remarks  </p>\n<ul>\n<li>only compare nodes that are of the same parent</li>\n<li>compare their raw scores not their UCB values<ul>\n<li>If you use UCB scores, then the mean and standard deviation of a move are those calculated only from its un-pruned children</li>\n</ul>\n</li>\n<li>prune statistically inferior moves after enough number of times of simulation</li>\n</ul>\n<p>This process is stopped when  </p>\n<ul>\n<li>there is only one move left</li>\n<li>the moves left are statistically equal</li>\n<li>a maximal threshold(like 10000 multiplied by the number of legal moves) of iterations is reached</li>\n</ul>\n<p>Two different pruning rules  </p>\n<ul>\n<li>Hard: a pruned move cannot be a candidate later on</li>\n<li>Soft: a move pruned at a given time <strong>can be a candidate later on</strong> if its value is no longer statistically inferior to a currently active move<ul>\n<li>Periodically check whether to reactive it</li>\n</ul>\n</li>\n</ul>\n<p>Arguments  </p>\n<ul>\n<li><p>Selection of rd <img data-src=\"/img/TCG/uct-result2.png\" alt=\"\">   </p>\n<ul>\n<li>The greater rd is</li>\n<li>the less pruned the moves are</li>\n<li>the better the algorithm performs</li>\n<li>the slower at each play</li>\n</ul>\n</li>\n<li><p>Selection of σe <img data-src=\"/img/TCG/uct-result1.png\" alt=\"\"></p>\n<ul>\n<li>The smaller σe is</li>\n<li>the fewer equalities there are</li>\n<li>the better the algorithm performs</li>\n<li>the slower at each play</li>\n</ul>\n</li>\n<li><p>rd plays an important role in the move pruning process</p>\n</li>\n<li><p>σe is less sensitive</p>\n</li>\n<li><p>Another trick is progressive widening or progressive un-pruning</p>\n<ul>\n<li>A node is effective if enough simulations are done on it and its values are good</li>\n</ul>\n</li>\n<li><p>We can set threshold on whether to expand the best path, for exmaple</p>\n<ul>\n<li>enough simulations are done</li>\n<li>score is good enough</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"All-moves-at-first-AMAF\"><a href=\"#All-moves-at-first-AMAF\" class=\"headerlink\" title=\"All moves at first(AMAF)\"></a>All moves at first(AMAF)</h4><ul>\n<li>score is used for <strong>all moves the same player played in a random game</strong><ul>\n<li>in this example, after simulate r→v→y→u→w, w which  has parent v and u which has parent r will be updated, too <img data-src=\"/img/TCG/amaf.png\" alt=\"\"></li>\n</ul>\n</li>\n<li>Advantage<ul>\n<li>speeding up the experiments</li>\n</ul>\n</li>\n<li>Drawback<ul>\n<li>not the same move - move in early game is not equal to late game </li>\n<li>Recapturing<ul>\n<li>Order of moves is important for certain games(圍棋)</li>\n<li>Modification: if several moves are played at the same place because of captures, modify the statistics only for the player who played first </li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Refinement: RAVE    </p>\n<ul>\n<li>Let v1(m) be the score of a move m without using AMAF</li>\n<li>Let v2(m) be the score of a move m with AMAF</li>\n<li>Observations<ul>\n<li>v1(m) is good when suffcient number of simulations are starting with m</li>\n<li>v2(m) is a <strong>good guess for the true score</strong> of the move m<ul>\n<li>when <strong>approaching the end of a game</strong></li>\n<li>when <strong>too few simulations starting with m</strong></li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p>Rapid Action Value Estimate (RAVE)  </p>\n<ul>\n<li>revised score $v3(m) = a \\times v1(m) + (1-a) \\times v2(m)$</li>\n<li>can dynamically change a as the game goes<ul>\n<li>For example: a = min{1, Nm/10000}, where Nm is simulation times start from m<ul>\n<li>This means when Nm reaches 10000, then no RAVE is used</li>\n</ul>\n</li>\n<li>Works out better than setting a = 0(i.e. pure AMAF)</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"Node-expansion\"><a href=\"#Node-expansion\" class=\"headerlink\" title=\"Node expansion\"></a>Node expansion</h4><ul>\n<li>May decide to expand potentially good nodes judging from the<br>current statistics</li>\n<li>All ends: expand all possible children of a newly added node</li>\n<li>Visit count: delay the expansion of a node until it is visited a certain number of times</li>\n<li>Transition probability: delay the expansion of a node until its \\score” or estimated visit count is high comparing to its siblings</li>\n<li>Use the current value, variance and parent’s value to derive a good estimation using statistical methods<br>Expansion policy with some transition probability is much better than the \\all ends” or \\pure visit count” policy</li>\n</ul>\n<!-- ##Chap09 Other way to increase performance -->\n\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><span class=\"exturl\" data-url=\"aHR0cDovL3d3dy5paXMuc2luaWNhLmVkdS50dy9+dHNoc3UvdGNnLw==\">TSHsu講義 2014年版<i class=\"fa fa-external-link-alt\"></i></span></p>\n",
            "tags": [
                "電腦對局理論",
                "機器學習",
                "人工智慧",
                "圍棋",
                "象棋",
                "蒙地卡羅",
                "Alpha-Beta搜尋",
                "強化學習"
            ]
        }
    ]
}