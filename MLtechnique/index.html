<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: light)">
<meta name="theme-color" content="#222" media="(prefers-color-scheme: dark)"><meta name="generator" content="Hexo 6.3.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon.webp">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon.webp">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon.webp">
  <link rel="mask-icon" href="/img/favicon.webp" color="#222">
  <meta name="google-site-verification" content="45plYlJRhxb-g8Tl8seizYgih_JUsmcJRH6oJHplkj0">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Noto+Sans+TC:300,300italic,400,400italic,700,700italic%7CNoto+Color+Emoji:300,300italic,400,400italic,700,700italic%7CCormorant+Garamond:300,300italic,400,400italic,700,700italic%7CNoto+Serif+TC:300,300italic,400,400italic,700,700italic%7CFira+Code:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha256-DfWjNxDkM94fVBWx1H5BMMp0Zq7luBlV8QRcSES7s+0=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/green/pace-theme-barber-shop.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"gitqwerty777.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":true,"version":"8.12.1","exturl":true,"sidebar":{"position":"right","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"show_result":true,"style":"flat"},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":true,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":true,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInDown","sidebar":"fadeInRight"}},"prism":false,"i18n":{"placeholder":"搜尋...","empty":"我們無法找到任何有關 ${query} 的搜索結果","hits_time":"${hits} 找到 ${time} 個結果","hits":"找到 ${hits} 個結果"},"path":"/search.json","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":3,"unescape":false,"preload":false}}</script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/config.min.js"></script>

    <meta name="description" content="尚未寫完">
<meta property="og:type" content="article">
<meta property="og:title" content="機器學習技法">
<meta property="og:url" content="http://gitqwerty777.github.io/MLtechnique/index.html">
<meta property="og:site_name" content="QWERTY">
<meta property="og:description" content="尚未寫完">
<meta property="og:locale" content="zh_TW">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ml/bestline.webp">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ml/circle.webp">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ml/fat.webp">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ml/funtime1.webp">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ml/wtxx.webp">
<meta property="og:image" content="http://gitqwerty777.github.io/img/ml/distancexbw.webp">
<meta property="article:published_time" content="2014-11-21T13:40:00.000Z">
<meta property="article:modified_time" content="2014-11-21T13:40:00.000Z">
<meta property="article:author" content="qwerty">
<meta property="article:tag" content="機器學習">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://gitqwerty777.github.io/img/ml/bestline.webp">


<link rel="canonical" href="http://gitqwerty777.github.io/MLtechnique/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-TW","comments":true,"permalink":"http://gitqwerty777.github.io/MLtechnique/","path":"MLtechnique/","title":"機器學習技法"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>機器學習技法 | QWERTY</title>
  
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-51310670-1"></script>
  <script class="next-config" data-name="google_analytics" type="application/json">{"tracking_id":"UA-51310670-1","only_pageview":false}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/third-party/analytics/google-analytics.min.js"></script>
<script data-ad-client="ca-pub-7267358872858108" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>





  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
<link rel="alternate" href="/atom.xml" title="QWERTY" type="application/atom+xml">
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切換導航欄" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">QWERTY</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">Hello World!</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首頁</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>文章<span class="badge">64</span></a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>關於</a></li><li class="menu-item menu-item-rss"><a href="/atom.xml" rel="section"><i class="fas fa-rss-square fa-fw"></i>RSS</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>標籤<span class="badge">155</span></a></li><li class="menu-item menu-item-ptt標籤雲"><span class="exturl" data-url="aHR0cHM6Ly9xd2VydHk3NzcubWUvcHR0LXRhZy1jbG91ZC8="><i class="fas fa-hashtag fa-fw"></i>PTT標籤雲</span></li><li class="menu-item menu-item-支語警察"><a href="/foreign-terms-police" rel="section"><i class="fas fa-language fa-fw"></i>支語警察</a></li><li class="menu-item menu-item-英文聊天機器人"><span class="exturl" data-url="aHR0cHM6Ly9jaGF0Ym90LnF3ZXJ0eTc3Ny5tZQ=="><i class="fas fa-comment-dots fa-fw"></i>英文聊天機器人</span></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜尋
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜尋..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</div>
        
  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目錄
        </li>
        <li class="sidebar-nav-overview">
          本站概要
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap01-SVM"><span class="nav-number">1.</span> <span class="nav-text">Chap01 SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Standard-large-margin-hyperplane-problem"><span class="nav-number">1.1.</span> <span class="nav-text">Standard large-margin hyperplane problem</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Support-Vector-Machine-SVM"><span class="nav-number">1.2.</span> <span class="nav-text">Support Vector Machine(SVM)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chap02-dual-SVM"><span class="nav-number">1.3.</span> <span class="nav-text">Chap02 dual SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Standard-hard-margin-SVM-dual"><span class="nav-number">1.3.1.</span> <span class="nav-text">Standard hard-margin SVM dual</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#SVM-%E5%92%8C-PLA-%E6%AF%94%E8%BC%83"><span class="nav-number">1.3.2.</span> <span class="nav-text">SVM 和 PLA 比較</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chap03-Kernel-SVM"><span class="nav-number">1.4.</span> <span class="nav-text">Chap03 Kernel SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Kernel-Hard-Margin-SVM"><span class="nav-number">1.4.1.</span> <span class="nav-text">Kernel Hard-Margin SVM</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#polynomial-Kernel"><span class="nav-number">1.4.2.</span> <span class="nav-text">polynomial Kernel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#infinite-Kernel"><span class="nav-number">1.4.3.</span> <span class="nav-text">infinite Kernel</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Kernel%E9%81%B8%E6%93%87"><span class="nav-number">1.4.4.</span> <span class="nav-text">Kernel選擇</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chap04-Soft-Margin-SVM"><span class="nav-number">1.5.</span> <span class="nav-text">Chap04 Soft-Margin SVM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Kernel-Soft-Margin-SVM"><span class="nav-number">1.6.</span> <span class="nav-text">Kernel Soft Margin SVM</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#SVM-validation"><span class="nav-number">1.6.1.</span> <span class="nav-text">SVM validation</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chap05-Kernel-Logistic-SVM"><span class="nav-number">1.7.</span> <span class="nav-text">Chap05 Kernel Logistic SVM</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap-06-Support-Vector-Regression-SVR"><span class="nav-number">2.</span> <span class="nav-text">Chap 06 Support Vector Regression(SVR)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-SVM-Summary"><span class="nav-number">2.1.</span> <span class="nav-text">Linear, SVM Summary</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap07-Blending-and-Bagging"><span class="nav-number">3.</span> <span class="nav-text">Chap07 Blending and Bagging</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap08-Adaptive-Boosting"><span class="nav-number">4.</span> <span class="nav-text">Chap08 Adaptive Boosting</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap09-Decision-Tree"><span class="nav-number">5.</span> <span class="nav-text">Chap09 Decision Tree</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap10-Random-Forest"><span class="nav-number">6.</span> <span class="nav-text">Chap10 Random Forest</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%A2%9E%E5%8A%A0decision-tree-diversity"><span class="nav-number">6.1.</span> <span class="nav-text">增加decision tree diversity</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Out-of-bag"><span class="nav-number">6.2.</span> <span class="nav-text">Out-of-bag</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Feature-Selection"><span class="nav-number">6.3.</span> <span class="nav-text">Feature Selection</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap11-Gradient-Boost-Decision-Tree"><span class="nav-number">7.</span> <span class="nav-text">Chap11 Gradient Boost Decision Tree</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Chap12-Neural-Network"><span class="nav-number">8.</span> <span class="nav-text">Chap12 Neural Network</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="qwerty"
      src="/img/qwerty.webp">
  <p class="site-author-name" itemprop="name">qwerty</p>
  <div class="site-description" itemprop="description">Programming | Computer Science | Thought</div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">64</span>
          <span class="site-state-item-name">文章</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分類</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">155</span>
        <span class="site-state-item-name">標籤</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <span class="exturl" data-url="aHR0cDovL2dpdGh1Yi5jb20vZ2l0cXdlcnR5Nzc3" title="GitHub → http:&#x2F;&#x2F;github.com&#x2F;gitqwerty777"><i class="fab fa-github fa-fw"></i></span>
      </span>
      <span class="links-of-author-item">
        <span class="exturl" data-url="bWFpbHRvOmdvb2hjbDc3N0BnbWFpbC5jb20=" title="E-Mail → mailto:goohcl777@gmail.com"><i class="fa fa-envelope fa-fw"></i></span>
      </span>
  </div>
  <div class="cc-license site-overview-item animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLXNhLzQuMC9kZWVkLnpoX1RX"><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/big/by_nc_sa.svg" alt="Creative Commons"></span>
  </div>


  <div class="links-of-blogroll site-overview-item animated">
    <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
      Links
    </div>
    <ul class="links-of-blogroll-list">
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9xd2VydHk3NzcubWU=" title="https:&#x2F;&#x2F;qwerty777.me">My Main Page</span>
        </li>
        <li class="links-of-blogroll-item">
          <span class="exturl" data-url="aHR0cHM6Ly9saWZlLnF3ZXJ0eTc3Ny5tZQ==" title="https:&#x2F;&#x2F;life.qwerty777.me">My Second Blog -- Wysiwyg</span>
        </li>
    </ul>
  </div>

        </div>
      </div>
        <div class="back-to-top animated" role="button" aria-label="回到頂端">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>

  <span class="exturl github-corner" data-url="aHR0cHM6Ly9naXRodWIuY29tL2dpdHF3ZXJ0eTc3Nw==" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></span>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-TW">
    <link itemprop="mainEntityOfPage" href="http://gitqwerty777.github.io/MLtechnique/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/img/qwerty.webp">
      <meta itemprop="name" content="qwerty">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="QWERTY">
      <meta itemprop="description" content="Programming | Computer Science | Thought">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="機器學習技法 | QWERTY">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          機器學習技法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">發表於</span>

      <time title="創建時間：2014-11-21 21:40:00" itemprop="dateCreated datePublished" datetime="2014-11-21T21:40:00+08:00">2014-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分類於</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E7%AD%86%E8%A8%98/" itemprop="url" rel="index"><span itemprop="name">筆記</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="文章字數">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">文章字數：</span>
      <span>10k</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <blockquote>
<p>尚未寫完</p>
</blockquote>
<span id="more"></span>
<h2 id="Chap01-SVM">Chap01 SVM</h2>
<p>All line is the same using PLA, but WHICH line is best? <img data-src="/img/ml/bestline.webp" alt="" /><br />
→ 可以容忍的誤差愈大愈好(最近的點與分隔線的距離愈遠愈好) <img data-src="/img/ml/circle.webp" alt="" /><br />
→ fat hyperplane (large <strong>margin</strong>)(分隔線可以多寬) <img data-src="/img/ml/fat.webp" alt="" /></p>
<p>若只有兩個點，必通過兩點連線之中垂線 <img data-src="/img/ml/funtime1.webp" alt="" /></p>
<h3 id="Standard-large-margin-hyperplane-problem">Standard large-margin hyperplane problem</h3>
<p>max fatness(w) (max margin)<br />
= min distance($x_n$, w) (n = 1 ~ N)<br />
= min distance($x_n$, b, w) -- (1)<br />
因為 w0 不列入計算(w0 = 常數項參數 = 截距b, x0 必為 1)</p>
<p><img data-src="/img/ml/wtxx.webp" alt="" /><br />
$w^tx$ = 0 → x除去x0成為x' → $w^tx'$ + b = 0<br />
設x', x''都在$w^tx'$ + b = 0平面上，$w^tx'$ = -b, $w^tx''$ = -b → $w^t(x''-x')$ = 0<br />
$w^t$ 垂直於 $w^tx'$ + b = 0平面<br />
distance(x, b, w) = x 到 平面的距離 <img data-src="/img/ml/distancexbw.webp" alt="" /></p>
<p>單一data的distance: 因 $y_n(w^t x_n + b) &gt; 0$<br />
$distance(x_n, b, w) = (1/|w|) * y_n(w^t x_n + b)$ -- (2)</p>
<p>specialize<br />
令 $min y_n(w^t x_n + b) = 1$<br />
→ $distance(x_n, b, w) = 1/|w|$<br />
由式子(1),(2)可得 max margin = min distance(x_n, b, w) = 1/|w|<br />
條件為 $min y_n(w^t x_n + b) = 1$</p>
<p>放鬆條件<br />
$y_n(w_t x_n + b) &gt;= 1$ is necessary constraints for $ min y_n(w_t x_n + b) = 1$<br />
if all y_n(w_t x_n + b) &gt; p &gt; 1 -&gt; can generate more optimal answer (b/p, w/p) -&gt; distance 1/|w| is smaller<br />
so y_n(w_t x_n + b) &gt;= 1 → y_n(w_t x_n + b) = 1</p>
<p>max 1/|w| -&gt; min 1/2 * w_t *  w</p>
<p><img data-src="" alt="standard min bw" /></p>
<p>can solve w by solve N inequality</p>
<h3 id="Support-Vector-Machine-SVM">Support Vector Machine(SVM)</h3>
<p>只須找最近的點即可算出w<br />
support vector: bounary data(胖線的邊界點)</p>
<p>gradient? : not easy with constraints<br />
but we have:</p>
<ul>
<li>(convex) quadratic objective function(b, w)</li>
<li>linear constraints (b, w)</li>
</ul>
<p>can use quadratic programming (QP, 二次規劃): easy</p>
<p><img data-src="" alt="bw" /><br />
<img data-src="" alt="QP" /><br />
<img data-src="" alt="QP value" /></p>
<p>Linear Hard-Margin(all wxy &gt; 0) SVM<br />
<img data-src="" alt="regular" /><br />
the same as ‘weight-decay regularization’ within Ein = 0</p>
<p>Restricts Dichotomies(堅持胖的線): if margin &lt; p, no answer<br />
fewer dichotomies -&gt; small VC dim -&gt; better generalization</p>
<p><img data-src="" alt="circle" /><br />
最大胖度有極限：在圓上，最大 根號3/2<br />
<img data-src="" alt="dvc ap" /></p>
<p><img data-src="" alt="compare" /><br />
can be good with transform<br />
控制複雜度的方法！<br />
控制複雜度的方法！</p>
<h3 id="Chap02-dual-SVM">Chap02 dual SVM</h3>
<p>if d_trans is big, or infinite?(非常複雜的轉換)<br />
find: SVM without dependence of d_trans<br />
去除計算(b, w)與轉換函式複雜度的關係<br />
(QP of d_trans+1 variables -&gt; N variables)</p>
<p>Use lagrange multiplier: Dual SVM: 將lambda視為變數來解<br />
<img data-src="" alt="lagrange function" /><br />
<img data-src="" alt="SVM=" /><br />
若不符條件，則L()的sigma部分是正的，MaxL()為無限大<br />
若符條件，則L()的sigma部分最大值為0 -&gt; MaxL() = 1/2w^tw<br />
所以Min(MaxL()) = Min(1/2w^tw)</p>
<p>交換max min的位置，可求得原問題的下限<br />
<img data-src="" alt="" /></p>
<p>可以得到strong duality(強對偶關係，=)？<br />
若在二次規劃滿足constraint qualification</p>
<ol>
<li>convex</li>
<li>feasible(有解)</li>
<li>linear constraints</li>
</ol>
<p>則存在 primal-dual 最佳解(對左右邊均是最佳解)</p>
<p>Dual SVM 最佳解為？<br />
<img data-src="" alt="微分b=0" /><br />
b可以被消除(=0)<br />
<img data-src="" alt="微分wi=0" /><br />
w代入得<br />
<img data-src="" alt="w=" /></p>
<p>Karush-Kuhn-Tucker (KKT) conditions<br />
<img data-src="" alt="KKT" /><br />
primal-inner -&gt; an = 0 或 1-yn(wtzn+b) = 0(complementary slackness)<br />
=&gt; at optimal all ‘Lagrange terms’ disappear</p>
<p>用KKT求得a(原lambda)之後，即可得原來的(b, w)<br />
w = sigma anynzn<br />
b 僅有邊界(primal feasible)，但b = yn - wtzn when an &gt; 0 (primal-inner，代表必在SVM邊界上)</p>
<p>重訂support vector的條件(a_n &gt;0)<br />
<img data-src="" alt="sv &lt; sv" /><br />
=&gt; b, w 都可以只用SV求到</p>
<p>SVM:找到有用的點(SV)</p>
<h4 id="Standard-hard-margin-SVM-dual">Standard hard-margin SVM dual</h4>
<p>經過整理<br />
<img data-src="" alt="min 1/2" /><br />
現在有N個a, 並有N+1個條件了</p>
<p><img data-src="" alt="QP" /><br />
when N is big, qn,m is dense array and very big(N &gt;30000, use &gt;3G ram)<br />
use special QP solver</p>
<h4 id="SVM-和-PLA-比較">SVM 和 PLA 比較</h4>
<p><img data-src="" alt="pla" /><br />
w = linear combination of data =&gt; w represented by data<br />
SVM: represent w by only SV</p>
<p><img data-src="" alt="dual" /><br />
Primal: 對(b,w)做特別縮放<br />
Dual: 找到SV 和其 lagrange multiplier</p>
<p>問題：q_n,m 需要做O(d_trans)的運算，如何避免？</p>
<h3 id="Chap03-Kernel-SVM">Chap03 Kernel SVM</h3>
<p>(z_n^T)(z_m)如何算更快</p>
<p>轉換+內積 -&gt; Kernel function<br />
<img data-src="" alt="xxxxxxx" /><br />
use O(d) instead of O(d^2)</p>
<p><img data-src="" alt="kernel" /><br />
<img data-src="" alt="b=" /><br />
<img data-src="" alt="gsvm =" /><br />
用kernel簡化！(gsvm -&gt; 無w)</p>
<h4 id="Kernel-Hard-Margin-SVM">Kernel Hard-Margin SVM</h4>
<p><img data-src="" alt="kernel svm algo" /></p>
<h4 id="polynomial-Kernel">polynomial Kernel</h4>
<p>簡化的kernel: 對應到同等大小，不同幾何特性(如內積)的空間<br />
<img data-src="" alt="kernel" /><br />
r影響SV的選擇<br />
<img data-src="" alt="SELECTED sv" /></p>
<p><img data-src="" alt="high dim" /><br />
可以快速做高次轉換(和二次相同複雜度)</p>
<p>特例: linear只需用 K1 = (0+1xtx)^1</p>
<h4 id="infinite-Kernel">infinite Kernel</h4>
<p>taylor展開<br />
<img data-src="" alt="k(x,x')" /></p>
<p>無限維度的Gaussian Kernel (Radial Basis Funtion(RBF))<br />
<img data-src="" alt="g" /></p>
<p><img data-src="" alt="support vector mechanism" /><br />
large =&gt; sharp Gaussians =&gt; ‘overfit’?<br />
<img data-src="" alt="overfit " /></p>
<h4 id="Kernel選擇">Kernel選擇</h4>
<p>linear kernel: 等於沒有轉換，linear first, 計算快<br />
polynomial: 轉換過，限制小，strong physical control, 維度太大K會趨向極端值<br />
-&gt; 平常只用不大的維度<br />
infinite dimension:<br />
most powerful<br />
less numerical difficulty than poly(僅兩次式)<br />
one parameter only<br />
cons: mysterious -- no w , and too powerful</p>
<p>define new kernel is hard:<br />
Mercer's condition:<br />
<img data-src="" alt="mercer" /></p>
<h3 id="Chap04-Soft-Margin-SVM">Chap04 Soft-Margin SVM</h3>
<p>overfit reason: transform &amp; hard-margin(全分開)</p>
<p>Soft-Margin -- 容忍錯誤，有錯誤penalty，只有對的需要符合條件<br />
<img data-src="" alt="soft1" /></p>
<p>缺點：<br />
No QP anymore<br />
error大小:離fat boundary的距離</p>
<p>改良：求最小(犯錯的點與boundary的距離和)(linear constraint, can use QP)<br />
<img data-src="" alt="soft2" /></p>
<p>parameter C: large when want less violate margin<br />
small when want large margin, tolerate some violation</p>
<p>Soft-margin Dual: 將條件加入min中<br />
<img data-src="" alt="dual" /><br />
化簡後得到和dual svm相同的式子(不同條件)<br />
<img data-src="" alt="化簡後" /><br />
C is exactly the upper bound of an</p>
<h3 id="Kernel-Soft-Margin-SVM">Kernel Soft Margin SVM</h3>
<p>more flexible: always solvable<br />
<img data-src="" alt="algo" /></p>
<p>(3)-&gt;solve b:<br />
若as &lt; C(unbounded, free), 則b的求法和hard-margin一樣<br />
<img data-src="" alt="compare b = " /></p>
<p>但soft-margin還是會overfit...</p>
<p>physical meaning<br />
<img data-src="" alt="" /><br />
not SV(an = 0): C-an != 0 -&gt; En = 0<br />
unbounded SV(0 &lt; an &lt; C，口) -&gt; En = 0 -&gt; on fat boundary<br />
bounded SV(an = C, △) -&gt; En &gt;= 0(有違反，不在boundary上)<br />
-&gt; 只有bounded SV才可違反</p>
<p>difficult to optimize(C, r)</p>
<h4 id="SVM-validation">SVM validation</h4>
<p>leave-one-out error &lt;= #SV/N<br />
若移除non-SV的點，則得出的g不變<br />
-&gt; 可以靠此特性做參數選擇(不選#SV太大的)</p>
<h3 id="Chap05-Kernel-Logistic-SVM">Chap05 Kernel Logistic SVM</h3>
<p>實用library: linear:LIBLINEAR nonlinear:LIBSVM</p>
<p>將E替代 -&gt; 像是 L2 regularization<br />
<img data-src="" alt="" /><br />
<img data-src="" alt="" /></p>
<p>缺點：不能QP, 不能微分(難解)</p>
<p><img data-src="" alt="compare" /><br />
large margin &lt;=&gt; fewer choices &lt;=&gt; L2 regularization of short w<br />
soft margin &lt;=&gt; special err<br />
larger C(in soft-margin or in regularization) &lt;=&gt; smaller lagrange multiplier &lt;=&gt; less regularization</p>
<p>We can extend SVM to other learning models!</p>
<p>look (wtzn + b) as linear score(f(x) in PLA)<br />
<img data-src="" alt="red-blue" /><br />
we can have Err_svm is upper bound of Err0/1<br />
(hinge error measure)<br />
<img data-src="" alt="three graph" /></p>
<p><img data-src="" alt="errwsce" /><br />
Err_sce: 與svm相似的一個logistic regression<br />
<img data-src="" alt="errbound" /></p>
<p><img data-src="" alt="three compare" /><br />
L2 logistic regression is similar to SVM,<br />
所以SVM可以用來approximate Logistic regression?<br />
-&gt; SVM當作Log regression的起始點? 沒有比較快(SVM優點)<br />
-&gt; 將SVM答案當作Log的近似解(return theta(wx + b))? 沒有log reg的意義(maximum likelyhood)<br />
=&gt; 加兩個自由度，return theta(A*(wx+b) + B)<br />
-&gt; often A &gt; 0(同方向), B~=0(無位移)<br />
<img data-src="" alt="NEW LOGREG" /><br />
將原本的SVM視為一種轉換</p>
<p>Platt's Model<br />
<img data-src="" alt="PLATT" /><br />
kernel SVM在Z空間的解 -- 用Log Reg微調後 --&gt; 用來近似Log Reg在Z空間的解(並不是在z空間最好的解)</p>
<p>solve LogReg to get(A, B)</p>
<p>能使用kernel的關鍵：w為z的線性組合<br />
<img data-src="" alt="svm pla logreg by sgd" /></p>
<p>Representer Theorem: 若解L2-正規化問題，最佳w必為z的線性組合<br />
將w分為(與z垂直)+(與z平行), 希望w_垂直 = 0<br />
證：(原本的w) 和 (與z平行的w) 所得的err是一樣的(因為w_垂直 * z = 0)<br />
且w平行比較短<br />
所以min w 必(與z平行)<br />
<img data-src="" alt="" /><br />
結果：L2的linear model都可以用kernel解！</p>
<p>將w = sum(B*z) = sum(B*Kernel)代入logistic regression<br />
-&gt; 解B</p>
<p>Kernel Logistic Regression(KLR)<br />
= linear model of B<br />
<img data-src="" alt="special regularizer" /><br />
把 kernel當作轉換, kernel當作regularizer<br />
= linear model of w<br />
with embedded-in-kernel transform &amp; L2 regularizer<br />
把 kernel內部(z)當作轉換(?), L2-regularizer</p>
<p>警告：算出的B不會有很多零</p>
<p>soft margin SVM ~= L2 LOG REG, special error measure:hinge<br />
在z空間解log reg -&gt; 用representor theorem 轉換為一般log reg, 有代價</p>
<h2 id="Chap-06-Support-Vector-Regression-SVR">Chap 06 Support Vector Regression(SVR)</h2>
<p>ridge regression : 有regularized的regression<br />
如何加入kernel?</p>
<p>Kernel Ridge Regression<br />
<img data-src="" alt="solve ridge" /><br />
用representor theorem代入後得到regularization term 和 regression term</p>
<p><img data-src="" alt="梯度" /><br />
<img data-src="" alt="B=" /><br />
因為kernal必為為psd，所以B必有解 O(N^3)</p>
<p>g(x) = wz = sum(bz)z = sum(bk)</p>
<p>與linear的比較：<br />
kernel自由度高<br />
linear為O(d^3+d^2N)<br />
kernel和資料量有關，為O(N^3)，檔案大時不快</p>
<p>LS(least-squares)SVM = kernel ridge regression:<br />
和一般regression boundary差不多，但SV很多(B dense)<br />
=&gt; 代表計算時間長<br />
=&gt; 找一個sparse B?</p>
<p>tube regression:<br />
<img data-src="" alt="tube" /><br />
insensitive error:容忍一小段的差距(在誤差內err = 0，若超過, err只算超過的部分)<br />
error增加的速度變慢</p>
<p>學SVM，解QP, 用DUAL, KKT-&gt;sparse<br />
<img data-src="" alt="mimicking" /><br />
regulizer 和 超過tube上界的值，超過tube下界的值</p>
<p>參數：C(violation重視程度), tube範圍</p>
<p>作dual: lagrange multiplier + KKT condition<br />
<img data-src="" alt="dual --" /></p>
<p>在tube裡面的點：B=0<br />
=&gt; 只要tube夠寬，B為sparse</p>
<h3 id="Linear-SVM-Summary">Linear, SVM Summary</h3>
<p><img data-src="" alt="linear" /></p>
<p><img data-src="" alt="SVM" /><br />
first row: less used due to worse performance<br />
third row: less used due to dense B<br />
fourth row: popular in LIBSVM</p>
<h2 id="Chap07-Blending-and-Bagging">Chap07 Blending and Bagging</h2>
<p>Selection: rely on only once hypothesis<br />
Aggregation: mix or combine hypothesiss<br />
select trust-worthy from their usual performance<br />
=&gt; validation<br />
mix the prediction =&gt; vote with different weight of ballot<br />
combine predictions conditionally(when some situation, give more ballots to friend t)</p>
<p><img data-src="" alt="real function" /></p>
<p>Aggregation可做到：</p>
<ol>
<li>feature transform(?), 將hypothesis變強</li>
<li>regularization(?)<br />
控制 油門 和 煞車<br />
<img data-src="" alt="two lines" /></li>
</ol>
<p>uniform blending: 一種model一票，取平均<br />
證明可以比原本的Eout小: <img data-src="" alt="" /></p>
<p>一個演算法A的表現，可以用其hypothesis set中的&quot;共識&quot;來表示，等於共識的表現，加上共識的變異數，uniform blending就是將某些在A的hypothesis取平均(變成新的演算法A')來減少A'的變異數<br />
expected performance of A = expected deviation to consensus + performance of consensus</p>
<p>linear blending: 加權(線性)平均，權重&gt;0<br />
<img data-src="" alt="linear bledning for regression" /><br />
求類似linear regression的式子: 兩段式學習，先算出許多g，再做  linear regression -&gt; 得到答案G<br />
限制：權重a&gt;0 -&gt; 將error rate大的model反過來用(error rate = 99%, 取其相反答案即可將error rate = 1%)</p>
<p>any blending(stacking): 可用non-linear model(???)</p>
<pre><code>算出g1-, g2- ...   
phi-1 = (g1-, g2-, ...)   
transform validation data to Z = (phi-1(x), y)   
compuate g = AnyModel(Z, Y)   
return G = g(phi(x))
phi = (g1, g2 ... )
</code></pre>
<p>比較：linear blending</p>
<pre><code>compuate a = AnyModel(Z, Y)   
return G = a * phi(x)
</code></pre>
<p>learning: 邊學邊合，</p>
<p>bootstrapping: 從有限的資料模擬出新的資料<br />
bootstrap data: 從原本資料選擇N筆資料(可重複)<br />
Virtual aggregation<br />
bootstrap aggregation(bagging): 由bootstrap data訓練g，而非原資料<br />
-&gt; meta algorithm for [base algorithm(可使用不同演算法)]</p>
<p><img data-src="" alt="BAGGING pocket in action" /></p>
<h2 id="Chap08-Adaptive-Boosting">Chap08 Adaptive Boosting</h2>
<p>教小學生辨認蘋果:<br />
由一個演算法提供[會混淆的資料]<br />
由其他hypothesis提出一個不同的小規則來區分</p>
<p>給不同的data權重，會混淆的占較大比例，取min Ein = avg(Wn * err(xn, yn))，可用SVM, lin_reg, log_reg解Wn</p>
<p>gt = argmin(sum(ut * err))<br />
gt+1 = argmin(sum(ut+1 * err))</p>
<p>找完gt後，gt+1應該要找和gt不相似的-&gt;找ut+1使gt的err rate接近0.5(隨機)。<br />
<img data-src="" alt="construct to make gt random-like" /></p>
<p>err rate = 錯誤資料權重和 / (錯誤資料權重和 + 正確資料權重和) = 1/2<br />
=&gt; 希望 正確資料權重和 = 錯誤資料權重和<br />
在gt中正確的資料, 權重要乘(err rate)<br />
在gt中錯誤的資料, 權重要乘(1-err rate)<br />
如此一來兩者之和將會相等</p>
<p>若scale factor = S = sqrt((1-err rate) / err rate)<br />
incorrect *= S<br />
correct *= 1/S<br />
若 S&gt;1:<br />
→ err rate &lt;= 1/2<br />
→ incorrect↑, correct↓, close to 1/2</p>
<p><img data-src="" alt="preliminary algorithm" /><br />
u1 可設所有為1/N，得到min Ein<br />
G 設uniform會使成績變差</p>
<p>Adaptive Boosting(皮匠法)<br />
<img data-src="" alt="ADA BOOST" /><br />
邊做邊算at</p>
<p>希望愈好的gt，at愈大<br />
-&gt; 設at = ln(St) (S = scale)<br />
if(err rate == 1/2) -&gt; St = 1 -&gt; at = 0<br />
if(err rate == 0) -&gt; St = inf -&gt; at = inf</p>
<p>只要err rate &lt; 1/2 , 就可以參與投票：群眾的力量</p>
<p>adapative boosting 的 algorithm 選擇(不需強演算法):<br />
decision stump: 三個參數：which feature, threshold(線), direction(ox)，可以使Ein &lt;= 1/2</p>
<h2 id="Chap09-Decision-Tree">Chap09 Decision Tree</h2>
<p><img data-src="" alt="" /></p>
<p>Traditional learning model that realize conditional aggregation<br />
模仿人類決策過程</p>
<p>Path View:<br />
G = sum(q * g)<br />
q = condition (is x on this path?)<br />
g = base hypothesis, only constant, leaf in tree</p>
<p>Recursive View:<br />
G(x) = sum([b(x) == c] * Gc(x))<br />
G: full tree<br />
b: branching criteria<br />
Gc: sub-tree hypothesis</p>
<p>advantage: human-explainable, simple, efficient, missing feature handle, categorical features easily, multiclass easily<br />
disadvantage: heuristic, little theoretical<br />
Ex. C&amp;RT, C4.5, J48...</p>
<p><img data-src="" alt="basic decision tree algo" /><br />
four choices: number of branches, branching<br />
criteria, termination criteria, &amp; base hypothesis</p>
<p>C&amp;RT(Classification and Regression Tree):<br />
Tree which is fully-grown with constant leaves<br />
C = 2(binary tree)，可用decision stump<br />
gt(x) = 在此分類下output最有可能(出現最多次的yn or yn平均)<br />
-&gt; 分得愈純愈好(同一類的output皆相同)</p>
<p><img data-src="" alt="more simple choices - argmin" /><br />
impurity = 變異數 or 出現最多次的yn的比率<br />
<img data-src="" alt="for classification error" /><br />
popular to use :<br />
Gini for classification<br />
regression error for regression</p>
<p><img data-src="" alt="basic C&amp;RT" /><br />
terminate criteria:</p>
<ol>
<li>all yn is the same: impurity = 0</li>
<li>all xn the same: cannot cut</li>
</ol>
<p>if all xn different: Ein = 0<br />
low-level tree built with small D -&gt; overfit</p>
<p>regularizer: number of leaves<br />
argmin(Ein(G) + c * number of leaves(G))<br />
實作：一次剪一片葉子，選最好的</p>
<p>相較數字的feature, 處理類型問題較簡單</p>
<p>Surrogate(代理) branch:<br />
找一些與最好切法相近的，若data features missing, 則使用之</p>
<p><img data-src="" alt="圖" /><br />
與adaboost相比：片段切割，只在自身subtree切</p>
<h2 id="Chap10-Random-Forest">Chap10 Random Forest</h2>
<p>Random Forest = bagging + fully-grown random-subspace random-combination C&amp;RT decision tree</p>
<p>highly parallel, 減少 decision tree的variance</p>
<h3 id="增加decision-tree-diversity">增加decision tree diversity</h3>
<ol>
<li>
<p>random sample features from x(random subspace of X)<br />
-&gt; efficient, can be used for any learning models<br />
10000個features, 只用100個維度來learn</p>
</li>
<li>
<p>將 x 作 低維度random projection -&gt; 產生新的feature(斜線切割), random combination</p>
</li>
</ol>
<h3 id="Out-of-bag">Out-of-bag</h3>
<p>out-of-bag: not sampled after N drawings<br />
N個data抽N次，沒被抽到機率 ~= 1/e<br />
=&gt; 將沒抽到的DATA作g的validation(通常不做，因為g只為G的其中之一)<br />
=&gt; 將沒抽到的DATA作G的validation，Eoob = sum(err(G-(xn))) (G-不包含用到xn的g)<br />
<img data-src="" alt="Eoob(G)" /><br />
Eoob: self-validation</p>
<h3 id="Feature-Selection">Feature Selection</h3>
<p>want to remove redundant, irrelevant features...</p>
<p><strong>learn a subset-transform</strong> for the final hypothesis</p>
<p>advantage: interpretability, remove 'feature noise', efficient<br />
disadvantage: total computation time increase, 'select feature overfit', mis-interpretability(過度解釋)</p>
<p>decision tree: built-in feature selection</p>
<p>idea: rate importance of every features<br />
linear model: 看w的大小<br />
non-linear model: not easy to estimate</p>
<p>idea: random test<br />
put some random value into feature, check performance↓，下降愈多代表愈重要</p>
<p>random value</p>
<ul>
<li>by original P(X = x)</li>
<li>bootstrap, <strong>permutation</strong></li>
</ul>
<p>performance: 算很久<br />
importance(i) = Eoob(G, D) - Eoob(G, Dp) (Dp = data with permutation in xn_i)</p>
<p><img data-src="" alt="strength-correlation" /><br />
strength-correlation decomposition<br />
s = average voting margin(投票最多-投票第二多...) with G<br />
p = gt之間的相似度<br />
bias-variance decomposition</p>
<h2 id="Chap11-Gradient-Boost-Decision-Tree">Chap11 Gradient Boost Decision Tree</h2>
<h2 id="Chap12-Neural-Network">Chap12 Neural Network</h2>

    </div>

    
    
    
      


    <footer class="post-footer">
          <div class="followme">
  <span>歡迎訂閱RSS</span>

  <div class="social-list">

      <div class="social-item">
        <a target="_blank" class="social-link" href="/atom.xml">
          <span class="icon">
            <i class="fa fa-rss"></i>
          </span>

          <span class="label">RSS</span>
        </a>
      </div>
  </div>
</div>

          <div class="post-tags">
              <a href="/tags/%E6%A9%9F%E5%99%A8%E5%AD%B8%E7%BF%92/" rel="tag"><i class="fa fa-tag"></i> 機器學習</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/MLfoundation2/" rel="prev" title="機器學習基石(下)">
                  <i class="fa fa-chevron-left"></i> 機器學習基石(下)
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/computer-architecture2/" rel="next" title="計算機結構(下)">
                  計算機結構(下) <i class="fa fa-chevron-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






    
  <div class="comments" id="disqus_thread">
    <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
  </div>
  
</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 2014 – 
  <span itemprop="copyrightYear">2024</span>
  <span class="with-love">
    <i class="fab fa-free-code-camp"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">qwerty</span>
</div>
<div class="wordcount">
  <span class="post-meta-item">
    <span class="post-meta-item-icon">
      <i class="fa fa-chart-line"></i>
    </span>
      <span>總字數：</span>
    <span title="總字數">476k</span>
  </span>
</div>
  <div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9waXNjZXMv">NexT.Pisces</span> 強力驅動
  </div>
  <div class="addthis_inline_share_toolbox">
    <script src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-61c5cf9cb3476405" async="async"></script>
  </div>

    </div>
  </footer>

  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.5.0/pjax.min.js" integrity="sha256-3NkoLDrmHLTYj7csHIZSr0MHAFTXth7Ua/DDt4MRUAg=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.0.6/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/comments.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/motion.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/next-boot.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/pjax.min.js"></script>

  
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.0/search.js" integrity="sha256-vXZMYLEqsROAXkEw93GGIvaB2ab+QW6w3+1ahD9nXXA=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/third-party/search/local-search.min.js"></script>


  <script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":{"light":"forest","dark":"forest"},"js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/9.1.1/mermaid.min.js","integrity":"sha256-8L3O8tirFUa8Va4NSTAyIbHJeLd6OnlcxgupV9F77e0="}}</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/third-party/tags/mermaid.min.js"></script>


  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/third-party/pace.min.js"></script>

  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"ams","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.1/es5/tex-mml-chtml.js","integrity":"sha256-hlC2uSQYTmPsrzGZTEQEg9PZ1a/+SV6VBCTclohf2og="}}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/third-party/math/mathjax.min.js"></script>


<script class="next-config" data-name="disqus" type="application/json">{"enable":true,"shortname":"disqusforqwerty","count":false,"i18n":{"disqus":"disqus"}}</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-next/8.12.1/third-party/comments/disqus.min.js"></script>

</body>
</html>
